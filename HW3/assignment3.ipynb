{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Полносвязная нейронная сеть ( Fully-Connected Neural Network)\n",
    "\n",
    "2) Нормализация по мини-батчам (Batch normalization)\n",
    "\n",
    "3) Dropout\n",
    "\n",
    "4) Сверточные нейронные сети (Convolutional Networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лабораторные работы можно выполнять с использованием сервиса Google Colaboratory (https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d) или на локальном компьютере. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Полносвязная нейронная сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной лабораторной работе необходимо будет реализовать полносвязную нейронную сеть, используя модульный подход. Для каждого  слоя реализации прямого и обратного проходов алгоритма обратного распространения ошибки будут иметь следующий вид:\n",
    "\n",
    "```python\n",
    "def layer_forward(x, w):\n",
    "  \"\"\" Receive inputs x and weights w \"\"\"\n",
    "  # Do some computations ...\n",
    "  z = # ... some intermediate value\n",
    "  # Do some more computations ...\n",
    "  out = # the output\n",
    "   \n",
    "  cache = (x, w, z, out) # Values we need to compute gradients\n",
    "   \n",
    "  return out, cache\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "def layer_backward(dout, cache):\n",
    "  \"\"\"\n",
    "  Receive dout (derivative of loss with respect to outputs) and cache,\n",
    "  and compute derivative with respect to inputs.\n",
    "  \"\"\"\n",
    "  # Unpack cache values\n",
    "  x, w, z, out = cache\n",
    "  \n",
    "  # Use values in cache to compute derivatives\n",
    "  dx = # Derivative of loss with respect to x\n",
    "  dw = # Derivative of loss with respect to w\n",
    "  \n",
    "  return dx, dw\n",
    "```\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== You can safely ignore the message below if you are NOT working on ConvolutionalNetworks.ipynb ===========\n",
      "\tYou will need to compile a Cython extension for a portion of this assignment.\n",
      "\tThe instructions to do this will be given in a section of the notebook below.\n",
      "\tThere will be an option for Colab users and another for Jupyter (local) users.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts_.classifiers.fc_net import *\n",
    "\n",
    "from scripts_.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from scripts_.solver import Solver\n",
    "from scripts_.classifiers.cnn import *\n",
    "from scripts_.layers import *\n",
    "from scripts_.fast_layers import *\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)  \n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "def print_mean_std(x,axis=0):\n",
    "    print('  means: ', x.mean(axis=axis))\n",
    "    print('  stds:  ', x.std(axis=axis))\n",
    "    print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите данные из предыдущей лабораторной работы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "num_training = 5000\n",
    "train_subsample = list(range(num_training))\n",
    "x_train = x_train[train_subsample]\n",
    "y_train = y_train[train_subsample]\n",
    "\n",
    "num_test = 500\n",
    "test_subsample = list(range(num_test))\n",
    "x_test = x_test[test_subsample]\n",
    "y_test = y_test[test_subsample]\n",
    "\n",
    "# data = {\"X_train\": x_train, \"y_train\": y_train, \"X_test\": x_test, \"y_test\": y_test}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 28, 28) (1500,) (3500, 28, 28) (3500,) (500, 28, 28) (500,)\n"
     ]
    }
   ],
   "source": [
    "num_training = 5000\n",
    "val_shape = 0.3 *  y_train.shape[0]\n",
    "train_subsample = list(range(num_training))\n",
    "x_train, x_val =  np.array_split(x_train, [int(val_shape)])\n",
    "y_train, y_val = np.array_split(y_train, [int(val_shape)])\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)  # Изменение формы на (N, 3072)\n",
    "x_val = x_val.reshape(x_val.shape[0], -1)  \n",
    "\n",
    "data = {\"X_train\": x_train, \"y_train\": y_train, \"X_val\": x_val, \"y_val\": y_val,\"X_test\": x_test, \"y_test\": y_test}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для полносвязного слоя реализуйте прямой проход (метод affine_forward в scripts/layers.py). Протестируйте свою реализацию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_forward function:\n",
      "difference:  9.769849468192957e-10\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 2\n",
    "input_shape = (4, 5, 6)\n",
    "output_dim = 3\n",
    "\n",
    "input_size = num_inputs * np.prod(input_shape)\n",
    "weight_size = output_dim * np.prod(input_shape)\n",
    "\n",
    "x = np.linspace(-0.1, 0.5, num=input_size).reshape(num_inputs, *input_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=weight_size).reshape(np.prod(input_shape), output_dim)\n",
    "b = np.linspace(-0.3, 0.1, num=output_dim)\n",
    "\n",
    "out, _ = affine_forward(x, w, b)\n",
    "correct_out = np.array([[ 1.49834967,  1.70660132,  1.91485297],\n",
    "                        [ 3.25553199,  3.5141327,   3.77273342]])\n",
    "\n",
    "\n",
    "print('Testing affine_forward function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для полносвязного слоя реализуйте обратный проход (метод affine_backward в scripts/layers.py). Протестируйте свою реализацию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_backward function:\n",
      "dx error:  5.399100368651805e-11\n",
      "dw error:  9.904211865398145e-11\n",
      "db error:  2.4122867568119087e-11\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 2, 3)\n",
    "w = np.random.randn(6, 5)\n",
    "b = np.random.randn(5)\n",
    "dout = np.random.randn(10, 5)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "_, cache = affine_forward(x, w, b)\n",
    "dx, dw, db = affine_backward(dout, cache)\n",
    "\n",
    "print('Testing affine_backward function:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте прямой проход для слоя активации ReLU (relu_forward) и протестируйте его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_forward function:\n",
      "difference:  4.999999798022158e-08\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(-0.5, 0.5, num=12).reshape(3, 4)\n",
    "\n",
    "out, _ = relu_forward(x)\n",
    "correct_out = np.array([[ 0.,          0.,          0.,          0.,        ],\n",
    "                        [ 0.,          0.,          0.04545455,  0.13636364,],\n",
    "                        [ 0.22727273,  0.31818182,  0.40909091,  0.5,       ]])\n",
    "\n",
    "# Compare your output with ours. The error should be on the order of e-8\n",
    "print('Testing relu_forward function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте обратный проход для слоя активации ReLU (relu_backward ) и протестируйте его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_backward function:\n",
      "dx error:  3.2756349136310288e-12\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: relu_forward(x)[0], x, dout)\n",
    "\n",
    "_, cache = relu_forward(x)\n",
    "dx = relu_backward(dout, cache)\n",
    "\n",
    "# The error should be on the order of e-12\n",
    "print('Testing relu_backward function:')\n",
    "print('dx error: ', rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В скрипте /layer_utils.py приведены реализации прямого и обратного проходов для часто используемых комбинаций слоев. Например, за полносвязным слоем часто следует слой активации. Ознакомьтесь с функциями affine_relu_forward и affine_relu_backward, запустите код ниже и убедитесь, что ошибка порядка e-10 или ниже. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_relu_forward and affine_relu_backward:\n",
      "dx error:  2.299579177309368e-11\n",
      "dw error:  8.162011105764925e-11\n",
      "db error:  7.826724021458994e-12\n"
     ]
    }
   ],
   "source": [
    "from scripts_.layer_utils import affine_relu_forward, affine_relu_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 3, 4)\n",
    "w = np.random.randn(12, 10)\n",
    "b = np.random.randn(10)\n",
    "dout = np.random.randn(2, 10)\n",
    "\n",
    "out, cache = affine_relu_forward(x, w, b)\n",
    "dx, dw, db = affine_relu_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_relu_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_relu_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_relu_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "# Relative error should be around e-10 or less\n",
    "print('Testing affine_relu_forward and affine_relu_backward:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте двухслойную полносвязную сеть - класс TwoLayerNet в scripts/classifiers/fc_net.py . Проверьте свою реализацию, запустив код ниже. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing initialization ... \n",
      "Testing test-time forward pass ... \n",
      "Testing training loss (no regularization)\n",
      "Running numeric gradient check with reg =  0.0\n",
      "W1 relative error: 1.83e-08\n",
      "W2 relative error: 3.12e-10\n",
      "b1 relative error: 9.83e-09\n",
      "b2 relative error: 4.33e-10\n",
      "Running numeric gradient check with reg =  0.7\n",
      "W1 relative error: 2.53e-07\n",
      "W2 relative error: 2.85e-08\n",
      "b1 relative error: 1.56e-08\n",
      "b2 relative error: 7.76e-10\n"
     ]
    }
   ],
   "source": [
    "from scripts_.classifiers.fc_net import *\n",
    "\n",
    "np.random.seed(231)\n",
    "N, D, H, C = 3, 5, 50, 7\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=N)\n",
    "\n",
    "std = 1e-3\n",
    "model = TwoLayerNet(input_dim=D, hidden_dim=H, num_classes=C, weight_scale=std)\n",
    "\n",
    "print('Testing initialization ... ')\n",
    "W1_std = abs(model.params['W1'].std() - std)\n",
    "b1 = model.params['b1']\n",
    "W2_std = abs(model.params['W2'].std() - std)\n",
    "b2 = model.params['b2']\n",
    "assert W1_std < std / 10, 'First layer weights do not seem right'\n",
    "assert np.all(b1 == 0), 'First layer biases do not seem right'\n",
    "assert W2_std < std / 10, 'Second layer weights do not seem right'\n",
    "assert np.all(b2 == 0), 'Second layer biases do not seem right'\n",
    "\n",
    "print('Testing test-time forward pass ... ')\n",
    "model.params['W1'] = np.linspace(-0.7, 0.3, num=D*H).reshape(D, H)\n",
    "model.params['b1'] = np.linspace(-0.1, 0.9, num=H)\n",
    "model.params['W2'] = np.linspace(-0.3, 0.4, num=H*C).reshape(H, C)\n",
    "model.params['b2'] = np.linspace(-0.9, 0.1, num=C)\n",
    "X = np.linspace(-5.5, 4.5, num=N*D).reshape(D, N).T\n",
    "scores = model.loss(X)\n",
    "correct_scores = np.asarray(\n",
    "  [[11.53165108,  12.2917344,   13.05181771,  13.81190102,  14.57198434, 15.33206765,  16.09215096],\n",
    "   [12.05769098,  12.74614105,  13.43459113,  14.1230412,   14.81149128, 15.49994135,  16.18839143],\n",
    "   [12.58373087,  13.20054771,  13.81736455,  14.43418138,  15.05099822, 15.66781506,  16.2846319 ]])\n",
    "scores_diff = np.abs(scores - correct_scores).sum()\n",
    "assert scores_diff < 1e-6, 'Problem with test-time forward pass'\n",
    "\n",
    "print('Testing training loss (no regularization)')\n",
    "y = np.asarray([0, 5, 1])\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 3.4702243556\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with training-time loss'\n",
    "\n",
    "model.reg = 1.0\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 26.5948426952\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with regularization loss'\n",
    "# Errors should be around e-7 or less\n",
    "for reg in [0.0, 0.7]:\n",
    "  print('Running numeric gradient check with reg = ', reg)\n",
    "  model.reg = reg\n",
    "  loss, grads = model.loss(X, y)\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ознакомьтесь с API для обучения и тестирования моделей в scripts/solver.py . Используйте экземпляр класса Solver для обучения двухслойной полносвязной сети. Необходимо достичь минимум 50% верно классифицированных объектов на валидационном наборе. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Solver.__init__() takes 3 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 14\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscripts_\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m FullyConnectedNet(\n\u001b[0;32m     10\u001b[0m     [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m],\n\u001b[0;32m     11\u001b[0m     weight_scale\u001b[38;5;241m=\u001b[39mweight_scale,\n\u001b[0;32m     12\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m solver \u001b[38;5;241m=\u001b[39m \u001b[43mSolver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdate_rule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msgd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptim_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m solver\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[1;31mTypeError\u001b[0m: Solver.__init__() takes 3 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "# from cs231n.data_utils import get_CIFAR10_data\n",
    "weight_scale = 3e-2   # Experiment with this!\n",
    "learning_rate = 4e-3  # Experiment with this!\n",
    "\n",
    "from scripts_.classifiers.fc_net import FullyConnectedNet\n",
    "from scripts_.solver import *\n",
    "\n",
    "\n",
    "model = FullyConnectedNet(\n",
    "    [100, 100],\n",
    "    weight_scale=weight_scale,\n",
    "    dtype=np.float64\n",
    ")\n",
    "solver = Solver(\n",
    "    model,\n",
    "    x_train, y_train, x_val, y_val,\n",
    "    print_every=10,\n",
    "    num_epochs=20,\n",
    "    batch_size=25,\n",
    "    update_rule=\"sgd\",\n",
    "    optim_config={\"learning_rate\": learning_rate},\n",
    ")\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 210) loss: 2.346484\n",
      "(Epoch 0 / 35) train acc: 0.128000; val_acc: 0.157714\n",
      "(Epoch 1 / 35) train acc: 0.559000; val_acc: 0.536571\n",
      "(Epoch 2 / 35) train acc: 0.579000; val_acc: 0.589714\n",
      "(Epoch 3 / 35) train acc: 0.564000; val_acc: 0.570000\n",
      "(Epoch 4 / 35) train acc: 0.758000; val_acc: 0.711429\n",
      "(Epoch 5 / 35) train acc: 0.777000; val_acc: 0.778571\n",
      "(Epoch 6 / 35) train acc: 0.771000; val_acc: 0.750857\n",
      "(Epoch 7 / 35) train acc: 0.800000; val_acc: 0.788286\n",
      "(Epoch 8 / 35) train acc: 0.847000; val_acc: 0.815714\n",
      "(Epoch 9 / 35) train acc: 0.838000; val_acc: 0.823429\n",
      "(Epoch 10 / 35) train acc: 0.832000; val_acc: 0.835143\n",
      "(Epoch 11 / 35) train acc: 0.853000; val_acc: 0.837714\n",
      "(Epoch 12 / 35) train acc: 0.855000; val_acc: 0.838286\n",
      "(Epoch 13 / 35) train acc: 0.848000; val_acc: 0.843714\n",
      "(Epoch 14 / 35) train acc: 0.880000; val_acc: 0.852857\n",
      "(Epoch 15 / 35) train acc: 0.870000; val_acc: 0.855714\n",
      "(Epoch 16 / 35) train acc: 0.879000; val_acc: 0.857714\n",
      "(Iteration 101 / 210) loss: 0.551085\n",
      "(Epoch 17 / 35) train acc: 0.884000; val_acc: 0.860857\n",
      "(Epoch 18 / 35) train acc: 0.887000; val_acc: 0.862286\n",
      "(Epoch 19 / 35) train acc: 0.914000; val_acc: 0.864286\n",
      "(Epoch 20 / 35) train acc: 0.890000; val_acc: 0.867429\n",
      "(Epoch 21 / 35) train acc: 0.881000; val_acc: 0.863714\n",
      "(Epoch 22 / 35) train acc: 0.912000; val_acc: 0.867714\n",
      "(Epoch 23 / 35) train acc: 0.899000; val_acc: 0.860571\n",
      "(Epoch 24 / 35) train acc: 0.887000; val_acc: 0.866000\n",
      "(Epoch 25 / 35) train acc: 0.886000; val_acc: 0.869714\n",
      "(Epoch 26 / 35) train acc: 0.897000; val_acc: 0.868286\n",
      "(Epoch 27 / 35) train acc: 0.911000; val_acc: 0.869429\n",
      "(Epoch 28 / 35) train acc: 0.892000; val_acc: 0.871714\n",
      "(Epoch 29 / 35) train acc: 0.906000; val_acc: 0.871143\n",
      "(Epoch 30 / 35) train acc: 0.907000; val_acc: 0.873143\n",
      "(Epoch 31 / 35) train acc: 0.907000; val_acc: 0.871143\n",
      "(Epoch 32 / 35) train acc: 0.899000; val_acc: 0.874000\n",
      "(Epoch 33 / 35) train acc: 0.903000; val_acc: 0.871714\n",
      "(Iteration 201 / 210) loss: 0.405184\n",
      "(Epoch 34 / 35) train acc: 0.900000; val_acc: 0.872857\n",
      "(Epoch 35 / 35) train acc: 0.900000; val_acc: 0.876000\n"
     ]
    }
   ],
   "source": [
    "from scripts_.solver import *\n",
    "\n",
    "from scripts_.classifiers import *\n",
    "\n",
    "model = TwoLayerNet(hidden_dim = 200,reg = 0.5)\n",
    "solver = Solver(model, data,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                    'learning_rate': 1e-3,\n",
    "                },\n",
    "                lr_decay=0.95,\n",
    "                num_epochs=35, batch_size=250,\n",
    "                print_every=100)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# TODO: Use a Solver instance to train a TwoLayerNet that achieves at least  #\n",
    "# 50% accuracy on the validation set.                                        #\n",
    "##############################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "solver.train()\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(solver.train_acc_history, '-o', label='train')\n",
    "plt.plot(solver.val_acc_history, '-o', label='val')\n",
    "plt.plot([0.5] * len(solver.val_acc_history), 'k--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь реализуйте полносвязную сеть с произвольным числом скрытых слоев. Ознакомьтесь с классом FullyConnectedNet в scripts/classifiers/fc_net.py . Реализуйте инициализацию, прямой и обратный проходы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x: (array([[0.00303221, 0.01567412, 0.00501193, 0.29047701, 0.        ,\n",
      "               0.00846244, 0.13687321, 0.08670895, 0.        , 0.15333479,\n",
      "               0.07423436, 0.01138801, 0.        , 0.        , 0.        ,\n",
      "               0.        , 0.        , 0.        , 0.        , 0.22824173],\n",
      "              [0.        , 0.07242328, 0.        , 0.04746884, 0.08911829,\n",
      "               0.19741909, 0.        , 0.        , 0.13996117, 0.10426446,\n",
      "               0.        , 0.14019608, 0.02313242, 0.06848749, 0.00210143,\n",
      "               0.10211484, 0.        , 0.        , 0.        , 0.09774359]]),\n",
      "        array([[ 2.63113991e-02,  1.27266552e-02,  2.19024250e-02,\n",
      "               -4.96716455e-02, -3.11234051e-02,  5.33840733e-02,\n",
      "               -8.07424611e-02,  5.71809252e-02,  1.41586570e-02,\n",
      "               -5.18834256e-02,  3.17029190e-03,  1.90842744e-02,\n",
      "                5.85018509e-02,  5.51747328e-03,  2.25759366e-02,\n",
      "                5.29809662e-02,  5.59213278e-02,  4.28860963e-02,\n",
      "               -7.40499478e-02,  7.64703626e-02, -5.62113879e-02,\n",
      "               -3.04088427e-02, -4.98172123e-02,  9.12465454e-02,\n",
      "                6.13657798e-02, -1.43233033e-03,  5.82825172e-02,\n",
      "               -6.75022907e-03,  6.98938376e-02,  6.19498460e-02],\n",
      "              [ 4.38558683e-02, -1.46133689e-02,  3.93316372e-02,\n",
      "               -1.23829969e-02, -2.29777582e-03,  2.52416542e-02,\n",
      "                2.27749748e-03,  4.65337059e-02, -3.63989819e-02,\n",
      "               -1.34538293e-02, -5.20748828e-02, -5.44324773e-02,\n",
      "               -1.63147944e-02,  1.06754654e-02,  1.74127600e-02,\n",
      "                2.47382804e-02,  1.00073003e-01,  1.37896454e-01,\n",
      "                5.31156877e-02,  6.61573095e-02,  5.69971310e-03,\n",
      "               -4.55048380e-02,  1.36025246e-02,  1.22743530e-02,\n",
      "                1.04559861e-01,  4.45243192e-02,  8.28693047e-02,\n",
      "                1.13097537e-04, -5.49827215e-03,  4.46716807e-02],\n",
      "              [ 2.75234233e-03,  5.33172198e-02, -1.32253388e-02,\n",
      "                1.51588503e-02, -9.11811506e-02,  5.27049206e-02,\n",
      "                6.51400286e-02,  9.95917303e-02,  3.28622058e-02,\n",
      "                5.58317348e-03, -2.75289488e-02,  4.68633913e-02,\n",
      "                2.09550718e-02, -2.21707376e-02, -4.94956139e-03,\n",
      "               -7.01299900e-02, -4.61528760e-02, -5.91145506e-02,\n",
      "                2.71341418e-02,  5.43408495e-02,  7.48125513e-02,\n",
      "               -7.12577066e-02,  2.77173177e-02, -2.22217479e-02,\n",
      "                8.95658654e-02, -5.79857644e-02,  5.85948300e-02,\n",
      "                5.18311221e-02, -2.10244650e-02,  5.58587718e-02],\n",
      "              [-1.10742367e-02, -1.26114496e-01, -1.65304048e-02,\n",
      "               -5.72874294e-02,  7.28975019e-02,  7.13891731e-02,\n",
      "               -4.95160367e-02,  2.10927776e-02,  2.97276646e-02,\n",
      "               -9.68029740e-02,  2.47074497e-02,  1.85969892e-02,\n",
      "                8.77264782e-02,  6.10508580e-02,  2.41146179e-02,\n",
      "                8.19397127e-03, -3.14046468e-02, -5.10539424e-02,\n",
      "                4.56764377e-03, -3.74471591e-02, -7.77926277e-02,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running check with reg =  0\n",
      "X shape: (2, 15)\n",
      "scores shape: (2, 10)\n",
      "Shape of x[0]: (2, 20)\n",
      "Shape of dout: (2, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                1.16911739e-02, -2.92188203e-03,  2.24942481e-02,\n",
      "                1.04828651e-01,  1.95357472e-02,  6.29482828e-02,\n",
      "                4.27966999e-03,  7.93196730e-02, -1.61183128e-02],\n",
      "              [-1.28533524e-02,  1.91412060e-02,  3.31471996e-03,\n",
      "                6.41198426e-02,  9.69808177e-02, -2.23038960e-02,\n",
      "                7.46869285e-03,  3.25623195e-02, -1.35404214e-02,\n",
      "               -4.56213567e-02, -4.08050630e-03,  3.96368727e-02,\n",
      "               -6.35221622e-02, -1.32001555e-02,  1.20701355e-01,\n",
      "               -3.82784400e-02,  4.73125458e-02, -3.07269264e-02,\n",
      "                6.33758250e-03, -5.42136455e-02,  8.08026719e-02,\n",
      "               -4.21793727e-03,  1.21517801e-02, -5.20005619e-02,\n",
      "                6.77038405e-02, -1.66559399e-03,  4.90613308e-02,\n",
      "               -1.19561142e-02,  1.08412820e-01,  2.60853959e-02],\n",
      "              [-4.77605387e-03, -1.78166191e-02, -3.78013354e-02,\n",
      "                1.08673205e-01,  3.11728294e-02, -6.71468216e-02,\n",
      "               -4.30639288e-02,  3.97351660e-02, -2.26006166e-02,\n",
      "               -4.61302986e-02, -1.85046601e-02, -8.61642806e-02,\n",
      "                1.28854397e-01, -3.07921198e-02, -3.37682171e-02,\n",
      "                1.36947798e-02,  2.41776892e-02,  9.99028734e-03,\n",
      "                3.28263698e-02, -5.47074484e-02, -2.80792493e-02,\n",
      "                1.02924727e-02,  2.63882198e-02,  3.34309744e-03,\n",
      "                3.28122425e-03, -1.95050489e-03,  1.38537900e-02,\n",
      "                3.20927161e-02, -7.89433012e-02,  1.67005554e-02],\n",
      "              [ 6.99784784e-02, -2.12874606e-02, -2.84459386e-02,\n",
      "                3.57106899e-02, -2.55290890e-02, -4.25756152e-02,\n",
      "                4.70572310e-02,  8.66489988e-02, -4.37507213e-02,\n",
      "                9.16717596e-02,  8.10774208e-02,  2.93200667e-03,\n",
      "                8.58513212e-02, -1.08487337e-02, -2.56516993e-02,\n",
      "                2.55969566e-02, -8.08621818e-02,  3.87384899e-02,\n",
      "               -1.69132711e-02, -9.98426511e-03,  6.00808935e-02,\n",
      "                4.93133739e-02, -1.57624497e-01, -8.97629979e-02,\n",
      "               -1.42783103e-01, -3.58318404e-02,  2.75786231e-02,\n",
      "                2.47663077e-03,  7.27694793e-02, -3.89660174e-02],\n",
      "              [-5.43322913e-02,  1.84536201e-02, -1.27928539e-02,\n",
      "               -7.79533348e-02, -7.39162047e-02,  9.20992074e-04,\n",
      "                2.66220997e-02, -1.39113822e-02, -1.10798659e-02,\n",
      "               -7.52466832e-02,  6.17563394e-02,  1.44095549e-02,\n",
      "               -9.62734686e-02, -7.99969049e-02, -8.02301835e-02,\n",
      "                7.73965498e-02,  6.99913878e-02, -3.02421063e-02,\n",
      "                8.82440387e-02, -1.24633421e-03, -3.75844594e-03,\n",
      "               -2.49611460e-04, -3.72504021e-02, -1.70022959e-02,\n",
      "               -9.39051329e-03, -3.47889382e-02,  2.26012964e-02,\n",
      "                5.49429004e-03, -1.90447205e-02, -6.85889577e-02],\n",
      "              [-2.42194660e-02, -2.52474579e-02,  2.69897908e-02,\n",
      "               -2.92241126e-02,  1.00897888e-02,  3.57163048e-02,\n",
      "                9.58573205e-02,  4.21837483e-02,  1.11699823e-01,\n",
      "                8.07381115e-03, -4.44536713e-03, -4.41632553e-02,\n",
      "                3.04000860e-02,  1.06622672e-04,  2.71510498e-02,\n",
      "                5.96681788e-03, -1.38233310e-02, -4.90583504e-02,\n",
      "               -2.19721713e-02, -4.90231211e-02, -5.93431875e-02,\n",
      "               -2.00696502e-02, -3.43090201e-02,  3.40023565e-03,\n",
      "               -5.82828632e-02,  2.42261996e-02,  4.08838317e-02,\n",
      "               -7.28290810e-02, -3.03284167e-02,  4.83895696e-02],\n",
      "              [-9.48081936e-02, -6.08168561e-02,  7.02051009e-02,\n",
      "               -4.67230404e-02, -1.41101991e-02,  3.53315553e-02,\n",
      "               -1.26351616e-01,  7.29037969e-02, -1.49626890e-03,\n",
      "               -1.13043700e-02,  5.08435066e-02, -8.64680050e-02,\n",
      "                1.13835381e-01,  5.71575718e-02,  3.62102015e-02,\n",
      "               -3.52103952e-02,  2.84014993e-02,  3.60017236e-02,\n",
      "               -1.67421216e-02, -9.07696996e-02,  6.59237318e-02,\n",
      "                9.22575943e-02, -7.07460390e-02, -3.09543380e-02,\n",
      "               -3.01084549e-04,  7.87438390e-02, -5.72463395e-02,\n",
      "                5.79998003e-02, -2.65151830e-02,  4.42770366e-02],\n",
      "              [-5.05651197e-04, -6.59985539e-02, -4.04335531e-02,\n",
      "               -2.25301309e-02, -7.33389010e-03,  1.05107504e-02,\n",
      "                2.86223749e-02, -2.91710203e-02, -3.44373718e-02,\n",
      "               -3.08571783e-02,  8.65269346e-02,  3.13889044e-02,\n",
      "               -2.33737173e-02, -2.51420010e-02, -6.92433115e-02,\n",
      "                3.12471680e-02,  1.41770157e-02,  3.14629165e-03,\n",
      "                9.82189645e-03,  8.69395622e-02, -7.41593550e-02,\n",
      "                7.26923065e-02,  7.17672252e-02, -7.62838334e-02,\n",
      "                6.41516534e-03,  3.42994807e-02, -7.67634332e-03,\n",
      "                9.36483382e-02, -4.17070401e-02,  3.35095474e-02],\n",
      "              [ 3.19827304e-02, -2.33053658e-02,  4.72092726e-02,\n",
      "               -2.34786819e-02,  5.58735006e-03, -2.43349517e-02,\n",
      "               -2.54076458e-02, -2.07218406e-02, -4.56775306e-02,\n",
      "                3.00088575e-02,  3.49462697e-03, -6.26404570e-02,\n",
      "               -5.16652328e-02,  2.14646410e-02, -3.21951988e-02,\n",
      "                4.59506863e-03,  5.95267688e-02,  1.46918024e-02,\n",
      "               -5.64121460e-02,  5.17540324e-02,  6.09012875e-02,\n",
      "                1.05622253e-02,  5.45671002e-02,  1.34486179e-02,\n",
      "                7.48653176e-02, -3.70429200e-02, -3.30063671e-02,\n",
      "               -1.22372561e-02,  4.26939712e-02, -6.78033724e-02],\n",
      "              [ 3.24547795e-02, -1.97287528e-02,  6.14923710e-03,\n",
      "               -1.10620868e-02,  1.53049786e-02, -3.35727426e-02,\n",
      "               -1.89426909e-02, -1.10389237e-03,  6.58977038e-04,\n",
      "                4.31542342e-02,  1.38152495e-02, -4.80021546e-02,\n",
      "                1.82950561e-02, -1.29707593e-01,  2.05531886e-02,\n",
      "               -3.65276763e-02,  7.11853691e-03, -3.15236195e-02,\n",
      "               -1.98010725e-02, -1.18829385e-01,  5.91290821e-04,\n",
      "                2.97231692e-02, -9.57493259e-02,  4.73188978e-02,\n",
      "               -4.78086608e-03,  1.23990984e-01, -6.33448133e-03,\n",
      "                2.60600970e-02, -5.79547014e-02,  5.49954175e-03],\n",
      "              [-7.84833989e-02, -5.93232074e-02,  2.99962608e-02,\n",
      "                1.42996938e-02,  3.80191841e-03, -4.61435071e-02,\n",
      "                4.43054859e-02, -1.57497737e-02, -1.03153992e-01,\n",
      "               -4.21123227e-02, -3.72309465e-02,  5.03287402e-02,\n",
      "               -4.96887699e-02, -1.41743651e-02, -2.38823810e-02,\n",
      "               -1.56010072e-02, -2.51260725e-02, -3.61578134e-02,\n",
      "               -4.81286493e-02,  2.30264691e-02, -1.09295892e-02,\n",
      "               -1.31103972e-01, -9.96253411e-02, -2.53990371e-02,\n",
      "               -2.31715390e-02, -1.93317638e-02,  2.78760771e-02,\n",
      "                3.84191720e-02,  2.66108234e-02,  6.88051872e-02],\n",
      "              [-2.07345576e-02,  1.50378341e-02,  3.35503447e-02,\n",
      "               -6.12496191e-02, -1.04158127e-02,  1.93288392e-02,\n",
      "                2.72414473e-02, -3.70669984e-02,  3.12588296e-02,\n",
      "                1.07009726e-02,  3.77992898e-02, -1.48606956e-02,\n",
      "               -9.71185909e-02, -3.56871352e-02, -1.30117309e-01,\n",
      "               -2.39203922e-02,  7.33098152e-02, -1.98520024e-02,\n",
      "               -6.57703502e-03,  4.38204713e-02,  5.10647711e-03,\n",
      "               -3.76322642e-02,  7.52671685e-02, -4.98896138e-02,\n",
      "                2.53114532e-02,  2.91742274e-02, -5.06093289e-02,\n",
      "               -7.96247596e-02, -3.12741274e-02,  4.78879291e-02],\n",
      "              [ 1.33078969e-02,  1.63218888e-02, -7.93868317e-02,\n",
      "               -2.62537315e-02, -3.36051068e-02, -9.59050171e-03,\n",
      "               -1.43334457e-02,  8.27876500e-03,  4.48522962e-02,\n",
      "                6.29761507e-03, -3.32466164e-02, -1.10116822e-01,\n",
      "               -4.39677764e-02, -5.55083804e-02, -4.52448553e-02,\n",
      "               -1.23096683e-02,  1.69434841e-03, -2.52558044e-02,\n",
      "                2.06142418e-02, -7.09148363e-02, -1.16596010e-01,\n",
      "                1.09891647e-01,  3.17199005e-02,  2.48839120e-02,\n",
      "               -3.66662457e-03,  5.33646516e-02, -9.56330729e-02,\n",
      "                6.14302563e-02, -3.99350510e-02, -1.35126247e-02],\n",
      "              [-1.40902587e-02,  1.37397422e-02, -2.14896594e-02,\n",
      "                1.62691850e-02, -2.04656389e-02, -6.98061472e-02,\n",
      "                1.00323449e-03,  3.29072371e-02, -1.00066566e-03,\n",
      "               -3.74187525e-02,  8.07037355e-02,  1.60144961e-02,\n",
      "                1.15735618e-02,  3.13637565e-02,  4.03962952e-02,\n",
      "                6.17050812e-03, -6.20291610e-02, -7.31854844e-03,\n",
      "                1.11190105e-02, -3.21879138e-02, -1.65925918e-02,\n",
      "               -1.02411431e-02, -5.62949160e-02, -5.62644446e-02,\n",
      "               -2.85480411e-02,  5.38970193e-02, -6.94457810e-02,\n",
      "               -1.74103058e-02, -9.49887560e-05,  4.97759798e-02],\n",
      "              [ 4.47310875e-03,  4.90395975e-02,  3.34641512e-02,\n",
      "                7.97043963e-02,  6.64873364e-03,  8.32067767e-03,\n",
      "                3.96164226e-02,  8.83507415e-02, -2.27173562e-02,\n",
      "                2.01148073e-02,  1.90450204e-02,  1.82368215e-02,\n",
      "                2.40426602e-02, -4.87045161e-02,  6.38577278e-02,\n",
      "               -4.60390800e-02, -2.45576777e-03, -4.03024826e-02,\n",
      "               -8.90190721e-03, -2.69219864e-02,  2.03655949e-03,\n",
      "                3.53380240e-02, -2.11318639e-02,  2.09773324e-03,\n",
      "                4.18215202e-02, -5.76981108e-02, -3.50125709e-02,\n",
      "               -4.94139285e-02, -5.56521031e-02,  2.81641319e-02],\n",
      "              [ 2.11943711e-02,  6.38829994e-02, -2.86958841e-02,\n",
      "                2.42388293e-02, -4.59680515e-03,  1.80581520e-02,\n",
      "               -1.62902836e-02, -6.54235290e-02,  3.47917033e-02,\n",
      "                8.61927502e-02,  9.02886291e-02,  7.74122615e-03,\n",
      "               -2.31690807e-02,  6.82547073e-02,  8.94234244e-02,\n",
      "               -2.66693769e-03, -5.18252437e-03,  5.46651349e-02,\n",
      "               -4.83131922e-02,  9.79537157e-02,  5.13048765e-02,\n",
      "                4.09922217e-02,  1.23828637e-02,  4.96644652e-02,\n",
      "               -6.39777519e-03, -9.59639060e-03,  9.29709460e-03,\n",
      "               -1.60384930e-02, -1.03836673e-01, -6.58399651e-03],\n",
      "              [-4.16025847e-02, -3.43435346e-03,  3.72283580e-02,\n",
      "                2.93149188e-02,  2.32214894e-02, -5.99864185e-02,\n",
      "               -6.01315488e-02,  3.73302463e-02,  6.07343951e-02,\n",
      "               -3.45128023e-03,  4.96833940e-02, -7.81350502e-02,\n",
      "               -1.18766304e-02,  1.31774510e-01, -6.93117016e-03,\n",
      "               -4.08743352e-02,  5.25066507e-02, -2.84772783e-02,\n",
      "                7.35848301e-02, -6.28183705e-02,  2.99954778e-02,\n",
      "               -1.56555149e-02, -3.43626099e-02,  9.99819394e-03,\n",
      "               -3.38382885e-02, -7.09033944e-03,  1.35055721e-02,\n",
      "               -4.53871157e-02,  2.23546321e-02, -5.27681717e-03]]),\n",
      "        array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning check with reg = \u001b[39m\u001b[38;5;124m'\u001b[39m, reg)\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m FullyConnectedNet([H1, H2], input_dim\u001b[38;5;241m=\u001b[39mD, num_classes\u001b[38;5;241m=\u001b[39mC,\n\u001b[0;32m      9\u001b[0m                           reg\u001b[38;5;241m=\u001b[39mreg, weight_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-2\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m---> 11\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitial loss: \u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Most of the errors should be on the order of e-7 or smaller.   \u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# NOTE: It is fine however to see an error for W2 on the order of e-5\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# for the check when reg = 0.0\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\classifiers\\fc_net.py:382\u001b[0m, in \u001b[0;36mFullyConnectedNet.loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    380\u001b[0m         grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m dgamma\n\u001b[0;32m    381\u001b[0m         grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m dbeta\n\u001b[1;32m--> 382\u001b[0m     dhidden, dW, db \u001b[38;5;241m=\u001b[39m \u001b[43maffine_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m dW \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m    385\u001b[0m grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m db\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\layers.py:61\u001b[0m, in \u001b[0;36maffine_backward\u001b[1;34m(dout, cache)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maffine_backward\u001b[39m(dout, cache):\n\u001b[0;32m     46\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m    Computes the backward pass for an affine layer.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m    - db: Gradient with respect to b, of shape (M,)\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m     x, w, b \u001b[38;5;241m=\u001b[39m cache\n\u001b[0;32m     62\u001b[0m     dx, dw, db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# TODO: Implement the affine backward pass.                               #\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "for reg in [0, 3.14]:\n",
    "  print('Running check with reg = ', reg)\n",
    "  model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                            reg=reg, weight_scale=5e-2, dtype=np.float64)\n",
    "\n",
    "  loss, grads = model.loss(X, y)\n",
    "  print('Initial loss: ', loss)\n",
    "  \n",
    "  # Most of the errors should be on the order of e-7 or smaller.   \n",
    "  # NOTE: It is fine however to see an error for W2 on the order of e-5\n",
    "  # for the check when reg = 0.0\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x: (array([[0.        , 0.03555095, 0.0078659 , 0.        , 0.06470929,\n",
      "               0.03842171, 0.        , 0.        , 0.02712538, 0.00568727,\n",
      "               0.00656403, 0.        , 0.        , 0.        , 0.        ,\n",
      "               0.        , 0.        , 0.02277924, 0.00394966, 0.01246382,\n",
      "               0.        , 0.        , 0.        , 0.        , 0.00907012,\n",
      "               0.10834965, 0.02283056, 0.        , 0.        , 0.        ],\n",
      "              [0.00432494, 0.00241257, 0.0316519 , 0.01176466, 0.0222714 ,\n",
      "               0.01501672, 0.        , 0.        , 0.01103719, 0.00048515,\n",
      "               0.        , 0.        , 0.        , 0.00835672, 0.02084819,\n",
      "               0.00208005, 0.        , 0.        , 0.0059626 , 0.03429461,\n",
      "               0.06587098, 0.0036328 , 0.        , 0.01589484, 0.00759446,\n",
      "               0.01698137, 0.        , 0.00015749, 0.00100848, 0.01333484]]),\n",
      "        array([[-0.01680087, -0.07178951, -0.03269432, ...,  0.04338832,\n",
      "               -0.06865797,  0.00537226],\n",
      "              [ 0.08415184,  0.03402212, -0.02192329, ..., -0.03673383,\n",
      "               -0.0003153 ,  0.08719275],\n",
      "              [-0.01977299,  0.03879606, -0.00739502, ..., -0.01636311,\n",
      "               -0.06080228,  0.00400702],\n",
      "              ...,\n",
      "              [-0.01768198, -0.03713098,  0.03528382, ...,  0.03022314,\n",
      "               -0.0527659 ,  0.00197071],\n",
      "              [-0.0825378 , -0.0551976 ,  0.10452258, ..., -0.04122334,\n",
      "                0.04179359, -0.00364284],\n",
      "              [ 0.05284974, -0.01490799, -0.08487131, ..., -0.06555896,\n",
      "               -0.07945849, -0.00101094]]),\n",
      "        array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0.]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running check with reg =  0\n",
      "X shape: (2, 15)\n",
      "scores shape: (2, 10)\n",
      "Shape of x[0]: (40,)\n",
      "Shape of dout: (2, 40)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning check with reg = \u001b[39m\u001b[38;5;124m'\u001b[39m, reg)\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m FullyConnectedNet([H1, H2,H3], input_dim\u001b[38;5;241m=\u001b[39mD, num_classes\u001b[38;5;241m=\u001b[39mC,\n\u001b[0;32m      8\u001b[0m                           reg\u001b[38;5;241m=\u001b[39mreg, weight_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-2\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m---> 10\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitial loss: \u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(grads):\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\classifiers\\fc_net.py:382\u001b[0m, in \u001b[0;36mFullyConnectedNet.loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    380\u001b[0m         grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m dgamma\n\u001b[0;32m    381\u001b[0m         grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m dbeta\n\u001b[1;32m--> 382\u001b[0m     dhidden, dW, db \u001b[38;5;241m=\u001b[39m \u001b[43maffine_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m dW \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m    385\u001b[0m grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m db\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\layers.py:61\u001b[0m, in \u001b[0;36maffine_backward\u001b[1;34m(dout, cache)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maffine_backward\u001b[39m(dout, cache):\n\u001b[0;32m     46\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m    Computes the backward pass for an affine layer.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m    - db: Gradient with respect to b, of shape (M,)\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m     x, w, b \u001b[38;5;241m=\u001b[39m cache\n\u001b[0;32m     62\u001b[0m     dx, dw, db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# TODO: Implement the affine backward pass.                               #\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "N, D, H1, H2,H3, C = 2, 15, 20, 30,40, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "for reg in [0, 3.14]:\n",
    "  print('Running check with reg = ', reg)\n",
    "  model = FullyConnectedNet([H1, H2,H3], input_dim=D, num_classes=C,\n",
    "                            reg=reg, weight_scale=5e-2, dtype=np.float64)\n",
    "\n",
    "  loss, grads = model.loss(X, y)\n",
    "  print('Initial loss: ', loss)\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте добиться эффекта переобучения на небольшом наборе изображений (например, 50). Используйте трехслойную сеть со 100 нейронами на каждом скрытом слое. Попробуйте переобучить сеть, достигнув 100 % accuracy за 20 эпох. Для этого поэкспериментируйте с параметрами weight_scale и learning_rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x: (array([[11.87350156, 12.67197142,  0.41033509, ..., 61.77076181,\n",
      "                0.        ,  0.        ],\n",
      "              [ 0.        , 12.85599924,  0.        , ..., 60.67195707,\n",
      "                0.        ,  3.92748182],\n",
      "              [18.50646109, 19.99475414, 49.12127098, ...,  1.93469418,\n",
      "                2.50738301,  0.        ],\n",
      "              ...,\n",
      "              [13.15603714, 16.54474771, 12.04351797, ..., 19.22814875,\n",
      "                0.        , 16.20008984],\n",
      "              [ 0.        ,  7.61116197, 32.47960971, ..., 66.66645229,\n",
      "                0.        ,  0.        ],\n",
      "              [16.6560158 , 16.30859902, 22.35765615, ..., 21.21536   ,\n",
      "                0.        ,  6.8608544 ]]),\n",
      "        array([[-4.94611221e-03, -1.29899630e-02, -1.20600310e-02, ...,\n",
      "               -8.52683464e-03,  2.04412312e-02, -3.94713055e-03],\n",
      "              [ 7.44163602e-03,  6.94784573e-03, -3.90680711e-03, ...,\n",
      "                1.02437028e-02,  1.54625664e-02,  1.32222833e-02],\n",
      "              [-2.65096460e-02,  7.28134977e-03,  1.32703296e-02, ...,\n",
      "                7.15791428e-03,  9.17073509e-03,  1.12545832e-02],\n",
      "              ...,\n",
      "              [ 7.57113324e-03,  1.54194033e-02, -1.81874309e-06, ...,\n",
      "                1.49696068e-02,  7.68280736e-03,  5.86175451e-03],\n",
      "              [ 1.48377585e-03,  1.15254134e-02, -7.88185794e-03, ...,\n",
      "               -5.96609877e-03,  1.95712514e-03,  1.69206300e-02],\n",
      "              [-1.09383457e-02,  6.09807704e-03,  1.78410887e-03, ...,\n",
      "               -5.60654675e-03,  1.01517458e-02, -2.41887885e-03]]),\n",
      "        array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (25, 784)\n",
      "scores shape: (25, 10)\n",
      "Shape of x[0]: (100,)\n",
      "Shape of dout: (25, 100)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 23\u001b[0m\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m FullyConnectedNet([\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m],\n\u001b[0;32m     15\u001b[0m               weight_scale\u001b[38;5;241m=\u001b[39mweight_scale, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m     16\u001b[0m solver \u001b[38;5;241m=\u001b[39m Solver(model, small_data,\n\u001b[0;32m     17\u001b[0m                 print_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,\n\u001b[0;32m     18\u001b[0m                 update_rule\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m                 }\n\u001b[0;32m     22\u001b[0m          )\n\u001b[1;32m---> 23\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(solver\u001b[38;5;241m.\u001b[39mloss_history, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining loss history\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:263\u001b[0m, in \u001b[0;36mSolver.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m num_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs \u001b[38;5;241m*\u001b[39m iterations_per_epoch\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# Maybe print training loss\u001b[39;00m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;129;01mand\u001b[39;00m t \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:181\u001b[0m, in \u001b[0;36mSolver._step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train[batch_mask]\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Compute loss and gradient\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_history\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# Perform a parameter update\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\classifiers\\fc_net.py:377\u001b[0m, in \u001b[0;36mFullyConnectedNet.loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dropout:\n\u001b[0;32m    376\u001b[0m     dhidden \u001b[38;5;241m=\u001b[39m dropout_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n\u001b[1;32m--> 377\u001b[0m dhidden \u001b[38;5;241m=\u001b[39m \u001b[43mrelu_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalization \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    379\u001b[0m     dhidden, dgamma, dbeta \u001b[38;5;241m=\u001b[39m batchnorm_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\layers.py:131\u001b[0m, in \u001b[0;36mrelu_backward\u001b[1;34m(dout, cache)\u001b[0m\n\u001b[0;32m    129\u001b[0m x \u001b[38;5;241m=\u001b[39m cache\n\u001b[0;32m    130\u001b[0m ic(x)\n\u001b[1;32m--> 131\u001b[0m dx \u001b[38;5;241m=\u001b[39m dout \u001b[38;5;241m*\u001b[39m (\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m#                             END OF YOUR CODE                            #\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dx\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "# TODO: Use a three-layer Net to overfit 50 training examples by \n",
    "# tweaking just the learning rate and initialization scale.\n",
    "\n",
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "weight_scale = 1e-2   # Experiment with this!\n",
    "learning_rate = 1e-4  # Experiment with this!\n",
    "model = FullyConnectedNet([100, 100],\n",
    "              weight_scale=weight_scale, dtype=np.float64)\n",
    "solver = Solver(model, small_data,\n",
    "                print_every=10, num_epochs=20, batch_size=25,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate,\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторите эксперимент, описанный выше, для пятислойной сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (25, 784)\n",
      "scores shape: (25, 10)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 23\u001b[0m\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m FullyConnectedNet([\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m],\n\u001b[0;32m     15\u001b[0m                 weight_scale\u001b[38;5;241m=\u001b[39mweight_scale, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m     16\u001b[0m solver \u001b[38;5;241m=\u001b[39m Solver(model, small_data,\n\u001b[0;32m     17\u001b[0m                 print_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,\n\u001b[0;32m     18\u001b[0m                 update_rule\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m                 }\n\u001b[0;32m     22\u001b[0m          )\n\u001b[1;32m---> 23\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(solver\u001b[38;5;241m.\u001b[39mloss_history, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining loss history\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:263\u001b[0m, in \u001b[0;36mSolver.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m num_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs \u001b[38;5;241m*\u001b[39m iterations_per_epoch\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# Maybe print training loss\u001b[39;00m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;129;01mand\u001b[39;00m t \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:181\u001b[0m, in \u001b[0;36mSolver._step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train[batch_mask]\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Compute loss and gradient\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_history\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# Perform a parameter update\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\classifiers\\fc_net.py:377\u001b[0m, in \u001b[0;36mFullyConnectedNet.loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dropout:\n\u001b[0;32m    376\u001b[0m     dhidden \u001b[38;5;241m=\u001b[39m dropout_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n\u001b[1;32m--> 377\u001b[0m dhidden \u001b[38;5;241m=\u001b[39m \u001b[43mrelu_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalization \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    379\u001b[0m     dhidden, dgamma, dbeta \u001b[38;5;241m=\u001b[39m batchnorm_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\layers.py:127\u001b[0m, in \u001b[0;36mrelu_backward\u001b[1;34m(dout, cache)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# TODO: Implement the ReLU backward pass.                                 #\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[39;00m\n\u001b[0;32m    126\u001b[0m x \u001b[38;5;241m=\u001b[39m cache\n\u001b[1;32m--> 127\u001b[0m dx \u001b[38;5;241m=\u001b[39m dout \u001b[38;5;241m*\u001b[39m (\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m#                             END OF YOUR CODE                            #\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dx\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "# TODO: Use a five-layer Net to overfit 50 training examples by \n",
    "# tweaking just the learning rate and initialization scale.\n",
    "\n",
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "learning_rate = 2e-3  # Experiment with this!\n",
    "weight_scale = 1e-5   # Experiment with this!\n",
    "model = FullyConnectedNet([100, 100, 100, 100],\n",
    "                weight_scale=weight_scale, dtype=np.float64)\n",
    "solver = Solver(model, small_data,\n",
    "                print_every=10, num_epochs=20, batch_size=25,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate,\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделайте выводы по проведенному эксперименту. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее обновление весов проходило по правилу SGD. Теперь попробуйте реализовать стохастический градиентный спуск с импульсом (SGD+momentum). http://cs231n.github.io/neural-networks-3/#sgd Реализуйте sgd_momentum в scripts/optim.py  и запустите проверку. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_w error:  8.882347033505819e-09\n",
      "velocity error:  4.269287743278663e-09\n"
     ]
    }
   ],
   "source": [
    "from scripts.optim import sgd_momentum\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-3, 'velocity': v}\n",
    "next_w, _ = sgd_momentum(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [ 0.1406,      0.20738947,  0.27417895,  0.34096842,  0.40775789],\n",
    "  [ 0.47454737,  0.54133684,  0.60812632,  0.67491579,  0.74170526],\n",
    "  [ 0.80849474,  0.87528421,  0.94207368,  1.00886316,  1.07565263],\n",
    "  [ 1.14244211,  1.20923158,  1.27602105,  1.34281053,  1.4096    ]])\n",
    "expected_velocity = np.asarray([\n",
    "  [ 0.5406,      0.55475789,  0.56891579, 0.58307368,  0.59723158],\n",
    "  [ 0.61138947,  0.62554737,  0.63970526,  0.65386316,  0.66802105],\n",
    "  [ 0.68217895,  0.69633684,  0.71049474,  0.72465263,  0.73881053],\n",
    "  [ 0.75296842,  0.76712632,  0.78128421,  0.79544211,  0.8096    ]])\n",
    "\n",
    "# Should see relative errors around e-8 or less\n",
    "print('next_w error: ', rel_error(next_w, expected_next_w))\n",
    "print('velocity error: ', rel_error(expected_velocity, config['velocity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните результаты обучения шестислойной сети, обученной классическим градиентным спуском и адаптивным алгоритмом с импульсом. Какой алгоритм сходится быстрее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running with  sgd\n",
      "X shape: (100, 784)\n",
      "scores shape: (100, 10)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 23\u001b[0m\n\u001b[0;32m     15\u001b[0m   solver \u001b[38;5;241m=\u001b[39m Solver(model, small_data,\n\u001b[0;32m     16\u001b[0m                   num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     17\u001b[0m                   update_rule\u001b[38;5;241m=\u001b[39mupdate_rule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m                   },\n\u001b[0;32m     21\u001b[0m                   verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m   solvers[update_rule] \u001b[38;5;241m=\u001b[39m solver\n\u001b[1;32m---> 23\u001b[0m   \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m   \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     26\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:263\u001b[0m, in \u001b[0;36mSolver.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m num_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs \u001b[38;5;241m*\u001b[39m iterations_per_epoch\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# Maybe print training loss\u001b[39;00m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;129;01mand\u001b[39;00m t \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:181\u001b[0m, in \u001b[0;36mSolver._step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train[batch_mask]\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Compute loss and gradient\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_history\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# Perform a parameter update\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\classifiers\\fc_net.py:377\u001b[0m, in \u001b[0;36mFullyConnectedNet.loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dropout:\n\u001b[0;32m    376\u001b[0m     dhidden \u001b[38;5;241m=\u001b[39m dropout_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n\u001b[1;32m--> 377\u001b[0m dhidden \u001b[38;5;241m=\u001b[39m \u001b[43mrelu_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalization \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    379\u001b[0m     dhidden, dgamma, dbeta \u001b[38;5;241m=\u001b[39m batchnorm_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\layers.py:127\u001b[0m, in \u001b[0;36mrelu_backward\u001b[1;34m(dout, cache)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# TODO: Implement the ReLU backward pass.                                 #\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[39;00m\n\u001b[0;32m    126\u001b[0m x \u001b[38;5;241m=\u001b[39m cache\n\u001b[1;32m--> 127\u001b[0m dx \u001b[38;5;241m=\u001b[39m dout \u001b[38;5;241m*\u001b[39m (\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m#                             END OF YOUR CODE                            #\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dx\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "num_train = 4000\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "solvers = {}\n",
    "\n",
    "for update_rule in ['sgd', 'sgd_momentum']:\n",
    "  print('running with ', update_rule)\n",
    "  model = FullyConnectedNet([100, 100, 100, 100, 100], weight_scale=5e-2)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=5, batch_size=100,\n",
    "                  update_rule=update_rule,\n",
    "                  optim_config={\n",
    "                    'learning_rate': 5e-3,\n",
    "                  },\n",
    "                  verbose=True)\n",
    "  solvers[update_rule] = solver\n",
    "  solver.train()\n",
    "  print()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "for update_rule, solver in solvers.items():\n",
    "  plt.subplot(3, 1, 1)\n",
    "  plt.plot(solver.loss_history, 'o', label=\"loss_%s\" % update_rule)\n",
    "  \n",
    "  plt.subplot(3, 1, 2)\n",
    "  plt.plot(solver.train_acc_history, '-o', label=\"train_acc_%s\" % update_rule)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  plt.plot(solver.val_acc_history, '-o', label=\"val_acc_%s\" % update_rule)\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте алгоритмы RMSProp [1] and Adam [2] с коррекцией смещения  - методы rmsprop и adam . \n",
    "\n",
    "\n",
    "[1] Tijmen Tieleman and Geoffrey Hinton. \"Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude.\" COURSERA: Neural Networks for Machine Learning 4 (2012).\n",
    "\n",
    "[2] Diederik Kingma and Jimmy Ba, \"Adam: A Method for Stochastic Optimization\", ICLR 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_w error:  9.502645229894295e-08\n",
      "cache error:  2.6477955807156126e-09\n"
     ]
    }
   ],
   "source": [
    "# Test RMSProp implementation\n",
    "from scripts.optim import rmsprop\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "cache = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'cache': cache}\n",
    "next_w, _ = rmsprop(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [-0.39223849, -0.34037513, -0.28849239, -0.23659121, -0.18467247],\n",
    "  [-0.132737,   -0.08078555, -0.02881884,  0.02316247,  0.07515774],\n",
    "  [ 0.12716641,  0.17918792,  0.23122175,  0.28326742,  0.33532447],\n",
    "  [ 0.38739248,  0.43947102,  0.49155973,  0.54365823,  0.59576619]])\n",
    "expected_cache = np.asarray([\n",
    "  [ 0.5976,      0.6126277,   0.6277108,   0.64284931,  0.65804321],\n",
    "  [ 0.67329252,  0.68859723,  0.70395734,  0.71937285,  0.73484377],\n",
    "  [ 0.75037008,  0.7659518,   0.78158892,  0.79728144,  0.81302936],\n",
    "  [ 0.82883269,  0.84469141,  0.86060554,  0.87657507,  0.8926    ]])\n",
    "\n",
    "# You should see relative errors around e-7 or less\n",
    "print('next_w error: ', rel_error(expected_next_w, next_w))\n",
    "print('cache error: ', rel_error(expected_cache, config['cache']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_w error:  1.139887467333134e-07\n",
      "v error:  4.208314038113071e-09\n",
      "m error:  4.214963193114416e-09\n"
     ]
    }
   ],
   "source": [
    "# Test Adam implementation\n",
    "from scripts.optim import adam\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "m = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.7, 0.5, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'm': m, 'v': v, 't': 5}\n",
    "next_w, _ = adam(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [-0.40094747, -0.34836187, -0.29577703, -0.24319299, -0.19060977],\n",
    "  [-0.1380274,  -0.08544591, -0.03286534,  0.01971428,  0.0722929],\n",
    "  [ 0.1248705,   0.17744702,  0.23002243,  0.28259667,  0.33516969],\n",
    "  [ 0.38774145,  0.44031188,  0.49288093,  0.54544852,  0.59801459]])\n",
    "expected_v = np.asarray([\n",
    "  [ 0.69966,     0.68908382,  0.67851319,  0.66794809,  0.65738853,],\n",
    "  [ 0.64683452,  0.63628604,  0.6257431,   0.61520571,  0.60467385,],\n",
    "  [ 0.59414753,  0.58362676,  0.57311152,  0.56260183,  0.55209767,],\n",
    "  [ 0.54159906,  0.53110598,  0.52061845,  0.51013645,  0.49966,   ]])\n",
    "expected_m = np.asarray([\n",
    "  [ 0.48,        0.49947368,  0.51894737,  0.53842105,  0.55789474],\n",
    "  [ 0.57736842,  0.59684211,  0.61631579,  0.63578947,  0.65526316],\n",
    "  [ 0.67473684,  0.69421053,  0.71368421,  0.73315789,  0.75263158],\n",
    "  [ 0.77210526,  0.79157895,  0.81105263,  0.83052632,  0.85      ]])\n",
    "\n",
    "# You should see relative errors around e-7 or less\n",
    "print('next_w error: ', rel_error(expected_next_w, next_w))\n",
    "print('v error: ', rel_error(expected_v, config['v']))\n",
    "print('m error: ', rel_error(expected_m, config['m']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите пару глубоких сетей с испольованием RMSProp и Adam алгоритмов обновления весов и сравните результаты обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получите лучшую полносвязную сеть для классификации вашего набора данных. На наборе CIFAR-10 необходимо получить accuracy не ниже 50 % на валидационном наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with  adam\n",
      "X shape: (100, 784)\n",
      "scores shape: (100, 10)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 26\u001b[0m\n\u001b[0;32m     16\u001b[0m     solver \u001b[38;5;241m=\u001b[39m Solver(\n\u001b[0;32m     17\u001b[0m         model,\n\u001b[0;32m     18\u001b[0m         small_data,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     )\n\u001b[0;32m     25\u001b[0m     solvers[update_rule] \u001b[38;5;241m=\u001b[39m solver\n\u001b[1;32m---> 26\u001b[0m     \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     29\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m15\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:263\u001b[0m, in \u001b[0;36mSolver.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m num_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs \u001b[38;5;241m*\u001b[39m iterations_per_epoch\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# Maybe print training loss\u001b[39;00m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;129;01mand\u001b[39;00m t \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:181\u001b[0m, in \u001b[0;36mSolver._step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train[batch_mask]\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Compute loss and gradient\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_history\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# Perform a parameter update\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\classifiers\\fc_net.py:377\u001b[0m, in \u001b[0;36mFullyConnectedNet.loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dropout:\n\u001b[0;32m    376\u001b[0m     dhidden \u001b[38;5;241m=\u001b[39m dropout_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n\u001b[1;32m--> 377\u001b[0m dhidden \u001b[38;5;241m=\u001b[39m \u001b[43mrelu_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalization \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    379\u001b[0m     dhidden, dgamma, dbeta \u001b[38;5;241m=\u001b[39m batchnorm_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\layers.py:127\u001b[0m, in \u001b[0;36mrelu_backward\u001b[1;34m(dout, cache)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# TODO: Implement the ReLU backward pass.                                 #\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[39;00m\n\u001b[0;32m    126\u001b[0m x \u001b[38;5;241m=\u001b[39m cache\n\u001b[1;32m--> 127\u001b[0m dx \u001b[38;5;241m=\u001b[39m dout \u001b[38;5;241m*\u001b[39m (\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m#                             END OF YOUR CODE                            #\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dx\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "################################################################################\n",
    "# TODO: Train the best FullyConnectedNet that you can on CIFAR-10. You might   #\n",
    "# find batch/layer normalization and dropout useful. Store your best model in  #\n",
    "# the best_model variable.                                                     #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "learning_rates = {'rmsprop': 1e-4, 'adam': 1e-3}\n",
    "for update_rule in ['adam', 'rmsprop']:\n",
    "    print('Running with ', update_rule)\n",
    "    model = FullyConnectedNet(\n",
    "        [100, 100, 100, 100, 100],\n",
    "        weight_scale=5e-2\n",
    "    )\n",
    "    solver = Solver(\n",
    "        model,\n",
    "        small_data,\n",
    "        num_epochs=5,\n",
    "        batch_size=100,\n",
    "        update_rule=update_rule,\n",
    "        optim_config={'learning_rate': learning_rates[update_rule]},\n",
    "        verbose=True\n",
    "    )\n",
    "    solvers[update_rule] = solver\n",
    "    solver.train()\n",
    "    print()\n",
    "    \n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 15))\n",
    "\n",
    "axes[0].set_title('Training loss')\n",
    "axes[0].set_xlabel('Iteration')\n",
    "axes[1].set_title('Training accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[2].set_title('Validation accuracy')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "\n",
    "for update_rule, solver in solvers.items():\n",
    "    axes[0].plot(solver.loss_history, label=f\"{update_rule}\")\n",
    "    axes[1].plot(solver.train_acc_history, label=f\"{update_rule}\")\n",
    "    axes[2].plot(solver.val_acc_history, label=f\"{update_rule}\")\n",
    "    \n",
    "for ax in axes:\n",
    "    ax.legend(loc='best', ncol=4)\n",
    "    ax.grid(linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получите оценку accuracy для валидационной и тестовой выборок. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(best_model.loss(data['X_test']), axis=1)\n",
    "y_val_pred = np.argmax(best_model.loss(data['X_val']), axis=1)\n",
    "print('Validation set accuracy: ', (y_val_pred == data['y_val']).mean())\n",
    "print('Test set accuracy: ', (y_test_pred == data['y_test']).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нормализация по мини-батчам\n",
    "\n",
    "Идея нормализации по мини-батчам предложена в работе [1]\n",
    "\n",
    "[1] Sergey Ioffe and Christian Szegedy, \"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\", ICML 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте прямой проход для слоя батч-нормализации - функция batchnorm_forward в scripts/layers.py . Проверьте свою реализацию, запустив следующий код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before batch normalization:\n",
      "  means:  [ -2.3814598  -13.18038246   1.91780462]\n",
      "  stds:   [27.18502186 34.21455511 37.68611762]\n",
      "\n",
      "After batch normalization (gamma=1, beta=0)\n",
      "  means:  [5.32907052e-17 7.04991621e-17 1.85962357e-17]\n",
      "  stds:   [0.99999999 1.         1.        ]\n",
      "\n",
      "After batch normalization (gamma= [1. 2. 3.] , beta= [11. 12. 13.] )\n",
      "  means:  [11. 12. 13.]\n",
      "  stds:   [0.99999999 1.99999999 2.99999999]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the training-time forward pass by checking means and variances\n",
    "# of features both before and after batch normalization   \n",
    "\n",
    "# Simulate the forward pass for a two-layer network\n",
    "np.random.seed(231)\n",
    "N, D1, D2, D3 = 200, 50, 60, 3\n",
    "X = np.random.randn(N, D1)\n",
    "W1 = np.random.randn(D1, D2)\n",
    "W2 = np.random.randn(D2, D3)\n",
    "a = np.maximum(0, X.dot(W1)).dot(W2)\n",
    "\n",
    "print('Before batch normalization:')\n",
    "print_mean_std(a,axis=0)\n",
    "\n",
    "gamma = np.ones((D3,))\n",
    "beta = np.zeros((D3,))\n",
    "# Means should be close to zero and stds close to one\n",
    "print('After batch normalization (gamma=1, beta=0)')\n",
    "a_norm, _ = batchnorm_forward(a, gamma, beta, {'mode': 'train'})\n",
    "print_mean_std(a_norm,axis=0)\n",
    "\n",
    "gamma = np.asarray([1.0, 2.0, 3.0])\n",
    "beta = np.asarray([11.0, 12.0, 13.0])\n",
    "# Now means should be close to beta and stds close to gamma\n",
    "print('After batch normalization (gamma=', gamma, ', beta=', beta, ')')\n",
    "a_norm, _ = batchnorm_forward(a, gamma, beta, {'mode': 'train'})\n",
    "print_mean_std(a_norm,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After batch normalization (test-time):\n",
      "  means:  [-0.03927354 -0.04349152 -0.10452688]\n",
      "  stds:   [1.01531428 1.01238373 0.97819988]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the test-time forward pass by running the training-time\n",
    "# forward pass many times to warm up the running averages, and then\n",
    "# checking the means and variances of activations after a test-time\n",
    "# forward pass.\n",
    "\n",
    "np.random.seed(231)\n",
    "N, D1, D2, D3 = 200, 50, 60, 3\n",
    "W1 = np.random.randn(D1, D2)\n",
    "W2 = np.random.randn(D2, D3)\n",
    "\n",
    "bn_param = {'mode': 'train'}\n",
    "gamma = np.ones(D3)\n",
    "beta = np.zeros(D3)\n",
    "\n",
    "for t in range(50):\n",
    "  X = np.random.randn(N, D1)\n",
    "  a = np.maximum(0, X.dot(W1)).dot(W2)\n",
    "  batchnorm_forward(a, gamma, beta, bn_param)\n",
    "\n",
    "bn_param['mode'] = 'test'\n",
    "X = np.random.randn(N, D1)\n",
    "a = np.maximum(0, X.dot(W1)).dot(W2)\n",
    "a_norm, _ = batchnorm_forward(a, gamma, beta, bn_param)\n",
    "\n",
    "# Means should be close to zero and stds close to one, but will be\n",
    "# noisier than training-time forward passes.\n",
    "print('After batch normalization (test-time):')\n",
    "print_mean_std(a_norm,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте обратный проход в функции batchnorm_backward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx error:  1.7029261167605239e-09\n",
      "dgamma error:  7.420414216247087e-13\n",
      "dbeta error:  2.8795057655839487e-12\n"
     ]
    }
   ],
   "source": [
    "# Gradient check batchnorm backward pass\n",
    "np.random.seed(231)\n",
    "N, D = 4, 5\n",
    "x = 5 * np.random.randn(N, D) + 12\n",
    "gamma = np.random.randn(D)\n",
    "beta = np.random.randn(D)\n",
    "dout = np.random.randn(N, D)\n",
    "\n",
    "bn_param = {'mode': 'train'}\n",
    "fx = lambda x: batchnorm_forward(x, gamma, beta, bn_param)[0]\n",
    "fg = lambda a: batchnorm_forward(x, a, beta, bn_param)[0]\n",
    "fb = lambda b: batchnorm_forward(x, gamma, b, bn_param)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "da_num = eval_numerical_gradient_array(fg, gamma.copy(), dout)\n",
    "db_num = eval_numerical_gradient_array(fb, beta.copy(), dout)\n",
    "\n",
    "_, cache = batchnorm_forward(x, gamma, beta, bn_param)\n",
    "dx, dgamma, dbeta = batchnorm_backward(dout, cache)\n",
    "#You should expect to see relative errors between 1e-13 and 1e-8\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dgamma error: ', rel_error(da_num, dgamma))\n",
    "print('dbeta error: ', rel_error(db_num, dbeta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Измените реализацию класса FullyConnectedNet, добавив батч-нормализацию. \n",
    "Если флаг normalization == \"batchnorm\", то вам необходимо вставить слой батч-нормализации перед каждым слоем активации ReLU, кроме выхода сети. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running check with reg =  0\n",
      "X shape: (2, 15)\n",
      "scores shape: (2, 10)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning check with reg = \u001b[39m\u001b[38;5;124m'\u001b[39m, reg)\n\u001b[0;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m FullyConnectedNet([H1, H2], input_dim\u001b[38;5;241m=\u001b[39mD, num_classes\u001b[38;5;241m=\u001b[39mC,\n\u001b[0;32m     12\u001b[0m                           reg\u001b[38;5;241m=\u001b[39mreg, weight_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-2\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[0;32m     13\u001b[0m                           normalization\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatchnorm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitial loss: \u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(grads):\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\classifiers\\fc_net.py:377\u001b[0m, in \u001b[0;36mFullyConnectedNet.loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dropout:\n\u001b[0;32m    376\u001b[0m     dhidden \u001b[38;5;241m=\u001b[39m dropout_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n\u001b[1;32m--> 377\u001b[0m dhidden \u001b[38;5;241m=\u001b[39m \u001b[43mrelu_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalization \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    379\u001b[0m     dhidden, dgamma, dbeta \u001b[38;5;241m=\u001b[39m batchnorm_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\layers.py:126\u001b[0m, in \u001b[0;36mrelu_backward\u001b[1;34m(dout, cache)\u001b[0m\n\u001b[0;32m    120\u001b[0m dx, x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, cache\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# TODO: Implement the ReLU backward pass.                                 #\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# print(\"Type of x:\", type(x))\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of x[0]:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of dout:\u001b[39m\u001b[38;5;124m\"\u001b[39m, dout\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    129\u001b[0m x \u001b[38;5;241m=\u001b[39m cache\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "# You should expect losses between 1e-4~1e-10 for W, \n",
    "# losses between 1e-08~1e-10 for b,\n",
    "# and losses between 1e-08~1e-09 for beta and gammas.\n",
    "for reg in [0, 3.14]:\n",
    "  print('Running check with reg = ', reg)\n",
    "  model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                            reg=reg, weight_scale=5e-2, dtype=np.float64,\n",
    "                            normalization='batchnorm')\n",
    "\n",
    "  loss, grads = model.loss(X, y)\n",
    "  print('Initial loss: ', loss)\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))\n",
    "  if reg == 0: print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите 6-ти слойную сеть на наборе из 1000 изображений с батч-нормализацией и без нее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver with batch norm:\n",
      "X shape: (50, 784)\n",
      "scores shape: (50, 10)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 25\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSolver with batch norm:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m bn_solver \u001b[38;5;241m=\u001b[39m Solver(bn_model, small_data,\n\u001b[0;32m     19\u001b[0m                 num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     20\u001b[0m                 update_rule\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m                 },\n\u001b[0;32m     24\u001b[0m                 verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,print_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mbn_solver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSolver without batch norm:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     28\u001b[0m solver \u001b[38;5;241m=\u001b[39m Solver(model, small_data,\n\u001b[0;32m     29\u001b[0m                 num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     30\u001b[0m                 update_rule\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m                 },\n\u001b[0;32m     34\u001b[0m                 verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, print_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:263\u001b[0m, in \u001b[0;36mSolver.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m num_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs \u001b[38;5;241m*\u001b[39m iterations_per_epoch\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# Maybe print training loss\u001b[39;00m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;129;01mand\u001b[39;00m t \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:181\u001b[0m, in \u001b[0;36mSolver._step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train[batch_mask]\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Compute loss and gradient\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_history\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# Perform a parameter update\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\classifiers\\fc_net.py:377\u001b[0m, in \u001b[0;36mFullyConnectedNet.loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dropout:\n\u001b[0;32m    376\u001b[0m     dhidden \u001b[38;5;241m=\u001b[39m dropout_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n\u001b[1;32m--> 377\u001b[0m dhidden \u001b[38;5;241m=\u001b[39m \u001b[43mrelu_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalization \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    379\u001b[0m     dhidden, dgamma, dbeta \u001b[38;5;241m=\u001b[39m batchnorm_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\layers.py:126\u001b[0m, in \u001b[0;36mrelu_backward\u001b[1;34m(dout, cache)\u001b[0m\n\u001b[0;32m    120\u001b[0m dx, x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, cache\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# TODO: Implement the ReLU backward pass.                                 #\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# print(\"Type of x:\", type(x))\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of x[0]:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of dout:\u001b[39m\u001b[38;5;124m\"\u001b[39m, dout\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    129\u001b[0m x \u001b[38;5;241m=\u001b[39m cache\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "# Try training a very deep net with batchnorm\n",
    "hidden_dims = [100, 100, 100, 100, 100]\n",
    "\n",
    "num_train = 1000\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "weight_scale = 2e-2\n",
    "bn_model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, normalization='batchnorm')\n",
    "model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, normalization=None)\n",
    "\n",
    "print('Solver with batch norm:')\n",
    "bn_solver = Solver(bn_model, small_data,\n",
    "                num_epochs=10, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True,print_every=20)\n",
    "bn_solver.train()\n",
    "\n",
    "print('\\nSolver without batch norm:')\n",
    "solver = Solver(model, small_data,\n",
    "                num_epochs=10, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=20)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте процесс обучения для двух сетей. Увеличилась ли скорость сходимости в случае с батч-нормализацией? Сделайте выводы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_training_history(title, label, baseline, bn_solvers, plot_fn, bl_marker='.', bn_marker='.', labels=None):\n",
    "    \"\"\"utility function for plotting training history\"\"\"\n",
    "    plt.title(title)\n",
    "    plt.xlabel(label)\n",
    "    bn_plots = [plot_fn(bn_solver) for bn_solver in bn_solvers]\n",
    "    bl_plot = plot_fn(baseline)\n",
    "    num_bn = len(bn_plots)\n",
    "    for i in range(num_bn):\n",
    "        label='with_norm'\n",
    "        if labels is not None:\n",
    "            label += str(labels[i])\n",
    "        plt.plot(bn_plots[i], bn_marker, label=label)\n",
    "    label='baseline'\n",
    "    if labels is not None:\n",
    "        label += str(labels[0])\n",
    "    plt.plot(bl_plot, bl_marker, label=label)\n",
    "    plt.legend(loc='lower center', ncol=num_bn+1) \n",
    "\n",
    "    \n",
    "plt.subplot(3, 1, 1)\n",
    "plot_training_history('Training loss','Iteration', solver, [bn_solver], \\\n",
    "                      lambda x: x.loss_history, bl_marker='o', bn_marker='o')\n",
    "plt.subplot(3, 1, 2)\n",
    "plot_training_history('Training accuracy','Epoch', solver, [bn_solver], \\\n",
    "                      lambda x: x.train_acc_history, bl_marker='-o', bn_marker='-o')\n",
    "plt.subplot(3, 1, 3)\n",
    "plot_training_history('Validation accuracy','Epoch', solver, [bn_solver], \\\n",
    "                      lambda x: x.val_acc_history, bl_marker='-o', bn_marker='-o')\n",
    "\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите 6-тислойную сеть с батч-нормализацией и без нее, используя разные размеры батча. Визуализируйте графики обучения. Сделайте выводы по результатам эксперимента. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x: (array([[0.00000000e+00, 4.37937260e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "               0.00000000e+00, 4.81449589e-02, 0.00000000e+00, 1.72147959e-01,\n",
      "               1.51555270e-01, 0.00000000e+00, 5.41352965e-02, 2.87043095e-01,\n",
      "               0.00000000e+00, 6.87242150e-02, 3.17153811e-01, 0.00000000e+00,\n",
      "               0.00000000e+00, 2.27669179e-01, 1.47597298e-01, 0.00000000e+00,\n",
      "               2.22718623e-02, 0.00000000e+00, 0.00000000e+00, 1.43943727e-01,\n",
      "               0.00000000e+00, 9.03022140e-02, 8.07640180e-02, 0.00000000e+00,\n",
      "               0.00000000e+00, 4.43605930e-02, 1.04976058e-01, 9.48973093e-03,\n",
      "               1.36274934e-01, 3.21908593e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "               0.00000000e+00, 0.00000000e+00, 1.33536756e-01, 1.69349328e-01,\n",
      "               0.00000000e+00, 1.85576648e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "               2.43079111e-01, 0.00000000e+00, 0.00000000e+00, 1.33270785e-01,\n",
      "               0.00000000e+00, 1.71348155e-01, 7.17422962e-02, 7.28776455e-02,\n",
      "               0.00000000e+00, 6.90342560e-02, 2.76042689e-02, 0.00000000e+00,\n",
      "               4.61451299e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "               0.00000000e+00, 7.92402178e-02, 0.00000000e+00, 2.80692220e-01,\n",
      "               2.04726249e-01, 9.39683616e-02, 1.99168980e-01, 0.00000000e+00,\n",
      "               2.45133489e-02, 1.00635983e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "               0.00000000e+00, 1.68196887e-01, 0.00000000e+00, 1.59844428e-01,\n",
      "               4.87209633e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "               1.06058665e-01, 1.29817232e-01, 1.57042772e-01, 0.00000000e+00,\n",
      "               5.73460571e-02, 0.00000000e+00, 2.80716009e-02, 2.11062595e-01,\n",
      "               7.70456791e-02, 0.00000000e+00, 7.51662068e-03, 0.00000000e+00,\n",
      "               0.00000000e+00, 2.06038594e-01, 9.00744721e-02, 1.83438569e-01,\n",
      "               3.11338194e-02, 9.47759449e-02, 7.86583647e-02, 0.00000000e+00],\n",
      "              [0.00000000e+00, 3.37079227e-01, 2.34902389e-02, 0.00000000e+00,\n",
      "               0.00000000e+00, 9.48833078e-02, 0.00000000e+00, 1.15118615e-01,\n",
      "               6.32872805e-02, 0.00000000e+00, 8.74878317e-02, 1.63123190e-01,\n",
      "               0.00000000e+00, 5.14741391e-02, 2.79916346e-01, 0.00000000e+00,\n",
      "               0.00000000e+00, 1.69112787e-01, 0.00000000e+00, 8.41751099e-02,\n",
      "               5.98130152e-02, 0.00000000e+00, 0.00000000e+00, 1.03547215e-01,\n",
      "               3.75885293e-02, 1.86175764e-01, 2.17424542e-01, 0.00000000e+00,\n",
      "               0.00000000e+00, 5.98430187e-02, 0.00000000e+00, 1.32823125e-01,\n",
      "               4.87691015e-02, 2.39723563e-01, 1.03010982e-01, 0.00000000e+00,\n",
      "               0.00000000e+00, 0.00000000e+00, 6.52104989e-02, 2.27769837e-04,\n",
      "               0.00000000e+00, 1.77692950e-01, 0.00000000e+00, 8.36019367e-02,\n",
      "               1.22718409e-01, 2.50426792e-02, 4.74992692e-02, 1.64650142e-01,\n",
      "               0.00000000e+00, 1.09266058e-01, 0.00000000e+00, 8.86535272e-02,\n",
      "               0.00000000e+00, 0.00000000e+00, 7.84261897e-02, 0.00000000e+00,\n",
      "               1.00469396e-01, 0.00000000e+00, 0.00000000e+00, 7.91958421e-02,\n",
      "               0.00000000e+00, 7.28672445e-02, 0.00000000e+00, 1.74435526e-01,\n",
      "               7.37636834e-02, 0.00000000e+00, 6.61402717e-02, 0.00000000e+00,\n",
      "               9.77305621e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "               0.00000000e+00, 2.29154199e-01, 0.00000000e+00, 1.82335645e-01,\n",
      "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "               5.61343208e-02, 1.43717229e-01, 1.88753664e-01, 0.00000000e+00,\n",
      "               0.00000000e+00, 0.00000000e+00, 1.24615744e-01, 6.99208528e-02,\n",
      "               0.00000000e+00, 0.00000000e+00, 5.78166023e-02, 0.00000000e+00,\n",
      "               0.00000000e+00, 2.72258341e-01, 0.00000000e+00, 2.66327888e-01,\n",
      "               3.95089276e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "              [0.00000000e+00, 2.20441446e-01, 3.07359602e-02, 0.00000000e+00,\n",
      "               0.00000000e+00, 5.45873418e-02, 1.03092149e-01, 1.37382030e-01,\n",
      "               5.16381674e-02, 0.00000000e+00, 1.01545230e-01, 6.12655878e-02,\n",
      "               0.00000000e+00, 1.14081576e-02, 2.19039202e-01, 0.00000000e+00,\n",
      "               0.00000000e+00, 1.54760331e-02, 0.00000000e+00, 1.96748320e-02,\n",
      "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.68904305e-01,\n",
      "               0.00000000e+00, 6.31746128e-02, 8.47738683e-02, 0.00000000e+00,\n",
      "               0.00000000e+00, 7.76700601e-02, 2.06661597e-02, 5.30351438e-02,\n",
      "               8.14053044e-02, 1.08322099e-01, 1.01770252e-01, 0.00000000e+00,\n",
      "               0.00000000e+00, 0.00000000e+00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No normalization: batch size =  5\n",
      "X shape: (5, 784)\n",
      "scores shape: (5, 10)\n",
      "Shape of x[0]: (100,)\n",
      "Shape of dout: (5, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ", 2.25097686e-03, 0.00000000e+00,\n",
      "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.34678560e-02,\n",
      "               1.03593513e-01, 0.00000000e+00, 1.59282684e-02, 9.45193022e-02,\n",
      "               0.00000000e+00, 1.62584912e-02, 0.00000000e+00, 2.67161410e-02,\n",
      "               0.00000000e+00, 0.00000000e+00, 1.04876474e-01, 0.00000000e+00,\n",
      "               3.71555239e-03, 0.00000000e+00, 0.00000000e+00, 1.01291850e-01,\n",
      "               0.00000000e+00, 6.94201961e-02, 0.00000000e+00, 1.89898580e-01,\n",
      "               9.67615545e-02, 0.00000000e+00, 3.80505137e-02, 0.00000000e+00,\n",
      "               8.35199803e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "               0.00000000e+00, 6.64299652e-02, 0.00000000e+00, 9.69566107e-02,\n",
      "               6.72671795e-02, 0.00000000e+00, 9.17764306e-02, 0.00000000e+00,\n",
      "               0.00000000e+00, 3.31974477e-02, 1.87839180e-01, 0.00000000e+00,\n",
      "               0.00000000e+00, 0.00000000e+00, 1.03337929e-01, 5.86011782e-02,\n",
      "               0.00000000e+00, 0.00000000e+00, 6.23464659e-02, 0.00000000e+00,\n",
      "               0.00000000e+00, 6.46740496e-02, 8.03766474e-02, 9.87321734e-02,\n",
      "               0.00000000e+00, 0.00000000e+00, 1.29854446e-02, 0.00000000e+00],\n",
      "              [0.00000000e+00, 2.31566191e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "               0.00000000e+00, 7.51200542e-02, 0.00000000e+00, 2.30131060e-01,\n",
      "               1.40071452e-01, 0.00000000e+00, 2.05855727e-01, 3.13526094e-01,\n",
      "               0.00000000e+00, 5.52289188e-02, 1.74723119e-01, 0.00000000e+00,\n",
      "               0.00000000e+00, 1.69498980e-01, 1.03098750e-01, 0.00000000e+00,\n",
      "               1.64659351e-01, 0.00000000e+00, 0.00000000e+00, 1.06713712e-01,\n",
      "               5.11593698e-03, 1.96620733e-01, 2.02399433e-01, 0.00000000e+00,\n",
      "               0.00000000e+00, 1.55871913e-01, 3.47853675e-02, 0.00000000e+00,\n",
      "               4.55260612e-02, 1.04109511e-01, 3.34012918e-02, 0.00000000e+00,\n",
      "               0.00000000e+00, 0.00000000e+00, 1.14448503e-01, 1.12949945e-01,\n",
      "               0.00000000e+00, 1.28539443e-01, 0.00000000e+00, 6.79484010e-03,\n",
      "               2.16802344e-01, 0.00000000e+00, 0.00000000e+00, 1.28886804e-01,\n",
      "               9.32197720e-02, 0.00000000e+00, 5.37642278e-02, 1.16232127e-01,\n",
      "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "               5.95359169e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.79517516e-02,\n",
      "               0.00000000e+00, 1.58877239e-01, 1.32878110e-01, 0.00000000e+00,\n",
      "               2.09236279e-01, 6.29476085e-02, 5.03172316e-02, 6.10781014e-02,\n",
      "               0.00000000e+00, 5.65425232e-02, 0.00000000e+00, 1.22008875e-01,\n",
      "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "               4.55330350e-02, 2.47914568e-01, 6.18583411e-02, 9.73235071e-03,\n",
      "               0.00000000e+00, 0.00000000e+00, 8.84196460e-02, 0.00000000e+00,\n",
      "               0.00000000e+00, 0.00000000e+00, 1.57269370e-02, 0.00000000e+00,\n",
      "               0.00000000e+00, 9.31189880e-02, 1.21739209e-01, 1.22165136e-01,\n",
      "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "              [0.00000000e+00, 2.44831413e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "               0.00000000e+00, 1.05236042e-02, 0.00000000e+00, 6.59875944e-02,\n",
      "               1.14123665e-01, 0.00000000e+00, 0.00000000e+00, 2.27600455e-01,\n",
      "               0.00000000e+00, 1.79874860e-02, 2.78994471e-01, 0.00000000e+00,\n",
      "               0.00000000e+00, 5.49655184e-02, 1.12415902e-01, 0.00000000e+00,\n",
      "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.12521300e-02,\n",
      "               6.61340132e-02, 1.09472372e-01, 3.78432684e-02, 0.00000000e+00,\n",
      "               1.04693234e-01, 8.96462128e-02, 0.00000000e+00, 0.00000000e+00,\n",
      "               1.23258427e-01, 3.07189822e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "               0.00000000e+00, 0.00000000e+00, 2.04615295e-01, 1.77760437e-01,\n",
      "               0.00000000e+00, 1.56541198e-01, 0.00000000e+00, 7.37240911e-02,\n",
      "               1.70702457e-01, 0.00000000e+00, 1.51925394e-02, 1.28361762e-01,\n",
      "               0.00000000e+00, 1.99771106e-01, 7.18302429e-02, 5.61831966e-02,\n",
      "               0.00000000e+00, 1.10394983e-02, 3.53033617e-02, 0.00000000e+00,\n",
      "               4.34323028e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "               0.00000000e+00, 7.30552599e-02, 0.00000000e+00, 1.93639919e-01,\n",
      "               1.74900681e-01, 0.00000000e+00, 8.86426941e-02, 0.00000000e+00,\n",
      "               0.00000000e+00, 1.16648257e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "               0.00000000e+00, 2.26088464e-01, 0.00000000e+00, 5.62141798e-02,\n",
      "               4.35122140e-02, 0.00000000e+00, 1.33161684e-02, 0.00000000e+00,\n",
      "               6.54259697e-02, 6.24542497e-02, 1.57007694e-01, 0.00000000e+00,\n",
      "               8.07886291e-03, 0.00000000e+00, 0.00000000e+00, 2.03597769e-01,\n",
      "               9.50537324e-02, 2.48931497e-02, 1.28188476e-01, 0.00000000e+00,\n",
      "               0.00000000e+00, 1.43380195e-01, 1.18302107e-01, 2.44530648e-01,\n",
      "               1.11048138e-02, 7.90144950e-02, 1.24937035e-01, 0.00000000e+00]],\n",
      "             dtype=float32),\n",
      "        array([[ 1.2203196e-02,  6.0433382e-03, -2.5142005e-02, ...,\n",
      "                1.5329834e-02, -7.5096772e-03, -3.4872729e-02],\n",
      "              [-1.1855498e-02,  1.3600508e-02, -7.9314085e-03, ...,\n",
      "                1.0456054e-02, -8.9058923e-03,  8.7495231e-05],\n",
      "              [-5.3499998e-03, -5.9088389e-03,  3.2003079e-02, ...,\n",
      "                2.7570924e-02,  2.7755101e-03, -1.4703796e-02],\n",
      "              ...,\n",
      "              [ 9.7694639e-03, -1.9305260e-03, -1.5895583e-02, ...,\n",
      "                9.6881427e-03, -1.3037561e-03, -2.3065975e-02],\n",
      "              [ 2.4009843e-03, -4.6586921e-03, -3.0114058e-02, ...,\n",
      "               -1.3701579e-03, -7.8881141e-03,  4.2177882e-02],\n",
      "              [-1.1903372e-02,  8.7710032e-03, -3.2281309e-02, ...,\n",
      "               -1.7604929e-03,  1.1196448e-02,  6.8182349e-03]], dtype=float32),\n",
      "        array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "             dtype=float32))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bn_solvers, solver, batch_sizes\n\u001b[0;32m     46\u001b[0m batch_sizes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m50\u001b[39m]\n\u001b[1;32m---> 47\u001b[0m bn_solvers_bsize, solver_bsize, batch_sizes \u001b[38;5;241m=\u001b[39m \u001b[43mrun_batchsize_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatchnorm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 27\u001b[0m, in \u001b[0;36mrun_batchsize_experiments\u001b[1;34m(normalization_mode)\u001b[0m\n\u001b[0;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m FullyConnectedNet(hidden_dims, weight_scale\u001b[38;5;241m=\u001b[39mweight_scale, normalization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m solver \u001b[38;5;241m=\u001b[39m Solver(model, small_data,\n\u001b[0;32m     21\u001b[0m                 num_epochs\u001b[38;5;241m=\u001b[39mn_epochs, batch_size\u001b[38;5;241m=\u001b[39msolver_bsize,\n\u001b[0;32m     22\u001b[0m                 update_rule\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m                 },\n\u001b[0;32m     26\u001b[0m                 verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 27\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m bn_solvers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch_sizes)):\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:263\u001b[0m, in \u001b[0;36mSolver.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m num_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs \u001b[38;5;241m*\u001b[39m iterations_per_epoch\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# Maybe print training loss\u001b[39;00m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;129;01mand\u001b[39;00m t \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:181\u001b[0m, in \u001b[0;36mSolver._step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train[batch_mask]\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Compute loss and gradient\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_history\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# Perform a parameter update\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\classifiers\\fc_net.py:377\u001b[0m, in \u001b[0;36mFullyConnectedNet.loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dropout:\n\u001b[0;32m    376\u001b[0m     dhidden \u001b[38;5;241m=\u001b[39m dropout_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n\u001b[1;32m--> 377\u001b[0m dhidden \u001b[38;5;241m=\u001b[39m \u001b[43mrelu_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalization \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    379\u001b[0m     dhidden, dgamma, dbeta \u001b[38;5;241m=\u001b[39m batchnorm_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\layers.py:131\u001b[0m, in \u001b[0;36mrelu_backward\u001b[1;34m(dout, cache)\u001b[0m\n\u001b[0;32m    129\u001b[0m x \u001b[38;5;241m=\u001b[39m cache\n\u001b[0;32m    130\u001b[0m ic(x)\n\u001b[1;32m--> 131\u001b[0m dx \u001b[38;5;241m=\u001b[39m dout \u001b[38;5;241m*\u001b[39m (\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m#                             END OF YOUR CODE                            #\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dx\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "def run_batchsize_experiments(normalization_mode):\n",
    "    np.random.seed(231)\n",
    "    # Try training a very deep net with batchnorm\n",
    "    hidden_dims = [100, 100, 100, 100, 100]\n",
    "    num_train = 1000\n",
    "    small_data = {\n",
    "      'X_train': data['X_train'][:num_train],\n",
    "      'y_train': data['y_train'][:num_train],\n",
    "      'X_val': data['X_val'],\n",
    "      'y_val': data['y_val'],\n",
    "    }\n",
    "    n_epochs=10\n",
    "    weight_scale = 2e-2\n",
    "    batch_sizes = [5,10,50]\n",
    "    lr = 10**(-3.5)\n",
    "    solver_bsize = batch_sizes[0]\n",
    "\n",
    "    print('No normalization: batch size = ',solver_bsize)\n",
    "    model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, normalization=None)\n",
    "    solver = Solver(model, small_data,\n",
    "                    num_epochs=n_epochs, batch_size=solver_bsize,\n",
    "                    update_rule='adam',\n",
    "                    optim_config={\n",
    "                      'learning_rate': lr,\n",
    "                    },\n",
    "                    verbose=False)\n",
    "    solver.train()\n",
    "    \n",
    "    bn_solvers = []\n",
    "    for i in range(len(batch_sizes)):\n",
    "        b_size=batch_sizes[i]\n",
    "        print('Normalization: batch size = ',b_size)\n",
    "        bn_model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, normalization=normalization_mode)\n",
    "        bn_solver = Solver(bn_model, small_data,\n",
    "                        num_epochs=n_epochs, batch_size=b_size,\n",
    "                        update_rule='adam',\n",
    "                        optim_config={\n",
    "                          'learning_rate': lr,\n",
    "                        },\n",
    "                        verbose=False)\n",
    "        bn_solver.train()\n",
    "        bn_solvers.append(bn_solver)\n",
    "        \n",
    "    return bn_solvers, solver, batch_sizes\n",
    "\n",
    "batch_sizes = [5,10,50]\n",
    "bn_solvers_bsize, solver_bsize, batch_sizes = run_batchsize_experiments('batchnorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'solver_bsize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m plot_training_history(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining accuracy (Batch Normalization)\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43msolver_bsize\u001b[49m, bn_solvers_bsize, \\\n\u001b[0;32m      3\u001b[0m                       \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mtrain_acc_history, bl_marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-^\u001b[39m\u001b[38;5;124m'\u001b[39m, bn_marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-o\u001b[39m\u001b[38;5;124m'\u001b[39m, labels\u001b[38;5;241m=\u001b[39mbatch_sizes)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      5\u001b[0m plot_training_history(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation accuracy (Batch Normalization)\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m, solver_bsize, bn_solvers_bsize, \\\n\u001b[0;32m      6\u001b[0m                       \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mval_acc_history, bl_marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-^\u001b[39m\u001b[38;5;124m'\u001b[39m, bn_marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-o\u001b[39m\u001b[38;5;124m'\u001b[39m, labels\u001b[38;5;241m=\u001b[39mbatch_sizes)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'solver_bsize' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plot_training_history('Training accuracy (Batch Normalization)','Epoch', solver_bsize, bn_solvers_bsize, \\\n",
    "                      lambda x: x.train_acc_history, bl_marker='-^', bn_marker='-o', labels=batch_sizes)\n",
    "plt.subplot(2, 1, 2)\n",
    "plot_training_history('Validation accuracy (Batch Normalization)','Epoch', solver_bsize, bn_solvers_bsize, \\\n",
    "                      lambda x: x.val_acc_history, bl_marker='-^', bn_marker='-o', labels=batch_sizes)\n",
    "\n",
    "plt.gcf().set_size_inches(15, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте прямой проход для dropout-слоя в scripts/layers.py\n",
    "\n",
    "http://cs231n.github.io/neural-networks-2/#reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests with p =  0.25\n",
      "Mean of input:  10.000207878477502\n",
      "Mean of train-time output:  10.014059116977283\n",
      "Mean of test-time output:  10.000207878477502\n",
      "Fraction of train-time output set to zero:  0.749784\n",
      "Fraction of test-time output set to zero:  0.0\n",
      "\n",
      "Running tests with p =  0.4\n",
      "Mean of input:  10.000207878477502\n",
      "Mean of train-time output:  9.977917658761159\n",
      "Mean of test-time output:  10.000207878477502\n",
      "Fraction of train-time output set to zero:  0.600796\n",
      "Fraction of test-time output set to zero:  0.0\n",
      "\n",
      "Running tests with p =  0.7\n",
      "Mean of input:  10.000207878477502\n",
      "Mean of train-time output:  9.987811912159426\n",
      "Mean of test-time output:  10.000207878477502\n",
      "Fraction of train-time output set to zero:  0.30074\n",
      "Fraction of test-time output set to zero:  0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(500, 500) + 10\n",
    "\n",
    "for p in [0.25, 0.4, 0.7]:\n",
    "  out, _ = dropout_forward(x, {'mode': 'train', 'p': p})\n",
    "  out_test, _ = dropout_forward(x, {'mode': 'test', 'p': p})\n",
    "\n",
    "  print('Running tests with p = ', p)\n",
    "  print('Mean of input: ', x.mean())\n",
    "  print('Mean of train-time output: ', out.mean())\n",
    "  print('Mean of test-time output: ', out_test.mean())\n",
    "  print('Fraction of train-time output set to zero: ', (out == 0).mean())\n",
    "  print('Fraction of test-time output set to zero: ', (out_test == 0).mean())\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте обратный проход для dropout-слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx relative error:  5.44560814873387e-11\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 10) + 10\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dropout_param = {'mode': 'train', 'p': 0.2, 'seed': 123}\n",
    "out, cache = dropout_forward(x, dropout_param)\n",
    "dx = dropout_backward(dout, cache)\n",
    "dx_num = eval_numerical_gradient_array(lambda xx: dropout_forward(xx, dropout_param)[0], x, dout)\n",
    "\n",
    "# Error should be around e-10 or less\n",
    "print('dx relative error: ', rel_error(dx, dx_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте в реализацию класса FullyConnectedNet поддержку dropout. Если параметр dropout != 1, то добавьте в модель dropout-слой после каждого слоя активации. Проверьте свою реализацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x: (array([[0.00303221, 0.01567412, 0.00501193, 0.29047701, 0.        ,\n",
      "               0.00846244, 0.13687321, 0.08670895, 0.        , 0.15333479,\n",
      "               0.07423436, 0.01138801, 0.        , 0.        , 0.        ,\n",
      "               0.        , 0.        , 0.        , 0.        , 0.22824173],\n",
      "              [0.        , 0.07242328, 0.        , 0.04746884, 0.08911829,\n",
      "               0.19741909, 0.        , 0.        , 0.13996117, 0.10426446,\n",
      "               0.        , 0.14019608, 0.02313242, 0.06848749, 0.00210143,\n",
      "               0.10211484, 0.        , 0.        , 0.        , 0.09774359]]),\n",
      "        array([[ 2.63113991e-02,  1.27266552e-02,  2.19024250e-02,\n",
      "               -4.96716455e-02, -3.11234051e-02,  5.33840733e-02,\n",
      "               -8.07424611e-02,  5.71809252e-02,  1.41586570e-02,\n",
      "               -5.18834256e-02,  3.17029190e-03,  1.90842744e-02,\n",
      "                5.85018509e-02,  5.51747328e-03,  2.25759366e-02,\n",
      "                5.29809662e-02,  5.59213278e-02,  4.28860963e-02,\n",
      "               -7.40499478e-02,  7.64703626e-02, -5.62113879e-02,\n",
      "               -3.04088427e-02, -4.98172123e-02,  9.12465454e-02,\n",
      "                6.13657798e-02, -1.43233033e-03,  5.82825172e-02,\n",
      "               -6.75022907e-03,  6.98938376e-02,  6.19498460e-02],\n",
      "              [ 4.38558683e-02, -1.46133689e-02,  3.93316372e-02,\n",
      "               -1.23829969e-02, -2.29777582e-03,  2.52416542e-02,\n",
      "                2.27749748e-03,  4.65337059e-02, -3.63989819e-02,\n",
      "               -1.34538293e-02, -5.20748828e-02, -5.44324773e-02,\n",
      "               -1.63147944e-02,  1.06754654e-02,  1.74127600e-02,\n",
      "                2.47382804e-02,  1.00073003e-01,  1.37896454e-01,\n",
      "                5.31156877e-02,  6.61573095e-02,  5.69971310e-03,\n",
      "               -4.55048380e-02,  1.36025246e-02,  1.22743530e-02,\n",
      "                1.04559861e-01,  4.45243192e-02,  8.28693047e-02,\n",
      "                1.13097537e-04, -5.49827215e-03,  4.46716807e-02],\n",
      "              [ 2.75234233e-03,  5.33172198e-02, -1.32253388e-02,\n",
      "                1.51588503e-02, -9.11811506e-02,  5.27049206e-02,\n",
      "                6.51400286e-02,  9.95917303e-02,  3.28622058e-02,\n",
      "                5.58317348e-03, -2.75289488e-02,  4.68633913e-02,\n",
      "                2.09550718e-02, -2.21707376e-02, -4.94956139e-03,\n",
      "               -7.01299900e-02, -4.61528760e-02, -5.91145506e-02,\n",
      "                2.71341418e-02,  5.43408495e-02,  7.48125513e-02,\n",
      "               -7.12577066e-02,  2.77173177e-02, -2.22217479e-02,\n",
      "                8.95658654e-02, -5.79857644e-02,  5.85948300e-02,\n",
      "                5.18311221e-02, -2.10244650e-02,  5.58587718e-02],\n",
      "              [-1.10742367e-02, -1.26114496e-01, -1.65304048e-02,\n",
      "               -5.72874294e-02,  7.28975019e-02,  7.13891731e-02,\n",
      "               -4.95160367e-02,  2.10927776e-02,  2.97276646e-02,\n",
      "               -9.68029740e-02,  2.47074497e-02,  1.85969892e-02,\n",
      "                8.77264782e-02,  6.10508580e-02,  2.41146179e-02,\n",
      "                8.19397127e-03, -3.14046468e-02, -5.10539424e-02,\n",
      "                4.56764377e-03, -3.74471591e-02, -7.77926277e-02,\n",
      "                1.16911739e-02, -2.92188203e-03,  2.24942481e-02,\n",
      "                1.04828651e-01,  1.95357472e-02,  6.29482828e-02,\n",
      "                4.27966999e-03,  7.93196730e-02, -1.61183128e-02],\n",
      "              [-1.28533524e-02,  1.91412060e-02,  3.31471996e-03,\n",
      "                6.41198426e-02,  9.69808177e-02,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running check with dropout =  1\n",
      "X shape: (2, 15)\n",
      "scores shape: (2, 10)\n",
      "Shape of x[0]: (30,)\n",
      "Shape of dout: (2, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " -2.23038960e-02,\n",
      "                7.46869285e-03,  3.25623195e-02, -1.35404214e-02,\n",
      "               -4.56213567e-02, -4.08050630e-03,  3.96368727e-02,\n",
      "               -6.35221622e-02, -1.32001555e-02,  1.20701355e-01,\n",
      "               -3.82784400e-02,  4.73125458e-02, -3.07269264e-02,\n",
      "                6.33758250e-03, -5.42136455e-02,  8.08026719e-02,\n",
      "               -4.21793727e-03,  1.21517801e-02, -5.20005619e-02,\n",
      "                6.77038405e-02, -1.66559399e-03,  4.90613308e-02,\n",
      "               -1.19561142e-02,  1.08412820e-01,  2.60853959e-02],\n",
      "              [-4.77605387e-03, -1.78166191e-02, -3.78013354e-02,\n",
      "                1.08673205e-01,  3.11728294e-02, -6.71468216e-02,\n",
      "               -4.30639288e-02,  3.97351660e-02, -2.26006166e-02,\n",
      "               -4.61302986e-02, -1.85046601e-02, -8.61642806e-02,\n",
      "                1.28854397e-01, -3.07921198e-02, -3.37682171e-02,\n",
      "                1.36947798e-02,  2.41776892e-02,  9.99028734e-03,\n",
      "                3.28263698e-02, -5.47074484e-02, -2.80792493e-02,\n",
      "                1.02924727e-02,  2.63882198e-02,  3.34309744e-03,\n",
      "                3.28122425e-03, -1.95050489e-03,  1.38537900e-02,\n",
      "                3.20927161e-02, -7.89433012e-02,  1.67005554e-02],\n",
      "              [ 6.99784784e-02, -2.12874606e-02, -2.84459386e-02,\n",
      "                3.57106899e-02, -2.55290890e-02, -4.25756152e-02,\n",
      "                4.70572310e-02,  8.66489988e-02, -4.37507213e-02,\n",
      "                9.16717596e-02,  8.10774208e-02,  2.93200667e-03,\n",
      "                8.58513212e-02, -1.08487337e-02, -2.56516993e-02,\n",
      "                2.55969566e-02, -8.08621818e-02,  3.87384899e-02,\n",
      "               -1.69132711e-02, -9.98426511e-03,  6.00808935e-02,\n",
      "                4.93133739e-02, -1.57624497e-01, -8.97629979e-02,\n",
      "               -1.42783103e-01, -3.58318404e-02,  2.75786231e-02,\n",
      "                2.47663077e-03,  7.27694793e-02, -3.89660174e-02],\n",
      "              [-5.43322913e-02,  1.84536201e-02, -1.27928539e-02,\n",
      "               -7.79533348e-02, -7.39162047e-02,  9.20992074e-04,\n",
      "                2.66220997e-02, -1.39113822e-02, -1.10798659e-02,\n",
      "               -7.52466832e-02,  6.17563394e-02,  1.44095549e-02,\n",
      "               -9.62734686e-02, -7.99969049e-02, -8.02301835e-02,\n",
      "                7.73965498e-02,  6.99913878e-02, -3.02421063e-02,\n",
      "                8.82440387e-02, -1.24633421e-03, -3.75844594e-03,\n",
      "               -2.49611460e-04, -3.72504021e-02, -1.70022959e-02,\n",
      "               -9.39051329e-03, -3.47889382e-02,  2.26012964e-02,\n",
      "                5.49429004e-03, -1.90447205e-02, -6.85889577e-02],\n",
      "              [-2.42194660e-02, -2.52474579e-02,  2.69897908e-02,\n",
      "               -2.92241126e-02,  1.00897888e-02,  3.57163048e-02,\n",
      "                9.58573205e-02,  4.21837483e-02,  1.11699823e-01,\n",
      "                8.07381115e-03, -4.44536713e-03, -4.41632553e-02,\n",
      "                3.04000860e-02,  1.06622672e-04,  2.71510498e-02,\n",
      "                5.96681788e-03, -1.38233310e-02, -4.90583504e-02,\n",
      "               -2.19721713e-02, -4.90231211e-02, -5.93431875e-02,\n",
      "               -2.00696502e-02, -3.43090201e-02,  3.40023565e-03,\n",
      "               -5.82828632e-02,  2.42261996e-02,  4.08838317e-02,\n",
      "               -7.28290810e-02, -3.03284167e-02,  4.83895696e-02],\n",
      "              [-9.48081936e-02, -6.08168561e-02,  7.02051009e-02,\n",
      "               -4.67230404e-02, -1.41101991e-02,  3.53315553e-02,\n",
      "               -1.26351616e-01,  7.29037969e-02, -1.49626890e-03,\n",
      "               -1.13043700e-02,  5.08435066e-02, -8.64680050e-02,\n",
      "                1.13835381e-01,  5.71575718e-02,  3.62102015e-02,\n",
      "               -3.52103952e-02,  2.84014993e-02,  3.60017236e-02,\n",
      "               -1.67421216e-02, -9.07696996e-02,  6.59237318e-02,\n",
      "                9.22575943e-02, -7.07460390e-02, -3.09543380e-02,\n",
      "               -3.01084549e-04,  7.87438390e-02, -5.72463395e-02,\n",
      "                5.79998003e-02, -2.65151830e-02,  4.42770366e-02],\n",
      "              [-5.05651197e-04, -6.59985539e-02, -4.04335531e-02,\n",
      "               -2.25301309e-02, -7.33389010e-03,  1.05107504e-02,\n",
      "                2.86223749e-02, -2.91710203e-02, -3.44373718e-02,\n",
      "               -3.08571783e-02,  8.65269346e-02,  3.13889044e-02,\n",
      "               -2.33737173e-02, -2.51420010e-02, -6.92433115e-02,\n",
      "                3.12471680e-02,  1.41770157e-02,  3.14629165e-03,\n",
      "                9.82189645e-03,  8.69395622e-02, -7.41593550e-02,\n",
      "                7.26923065e-02,  7.17672252e-02, -7.62838334e-02,\n",
      "                6.41516534e-03,  3.42994807e-02, -7.67634332e-03,\n",
      "                9.36483382e-02, -4.17070401e-02,  3.35095474e-02],\n",
      "              [ 3.19827304e-02, -2.33053658e-02,  4.72092726e-02,\n",
      "               -2.34786819e-02,  5.58735006e-03, -2.43349517e-02,\n",
      "               -2.54076458e-02, -2.07218406e-02, -4.56775306e-02,\n",
      "                3.00088575e-02,  3.49462697e-03, -6.26404570e-02,\n",
      "               -5.16652328e-02,  2.14646410e-02, -3.21951988e-02,\n",
      "                4.59506863e-03,  5.95267688e-02,  1.46918024e-02,\n",
      "               -5.64121460e-02,  5.17540324e-02,  6.09012875e-02,\n",
      "                1.05622253e-02,  5.45671002e-02,  1.34486179e-02,\n",
      "                7.48653176e-02, -3.70429200e-02, -3.30063671e-02,\n",
      "               -1.22372561e-02,  4.26939712e-02, -6.78033724e-02],\n",
      "              [ 3.24547795e-02, -1.97287528e-02,  6.14923710e-03,\n",
      "               -1.10620868e-02,  1.53049786e-02, -3.35727426e-02,\n",
      "               -1.89426909e-02, -1.10389237e-03,  6.58977038e-04,\n",
      "                4.31542342e-02,  1.38152495e-02, -4.80021546e-02,\n",
      "                1.82950561e-02, -1.29707593e-01,  2.05531886e-02,\n",
      "               -3.65276763e-02,  7.11853691e-03, -3.15236195e-02,\n",
      "               -1.98010725e-02, -1.18829385e-01,  5.91290821e-04,\n",
      "                2.97231692e-02, -9.57493259e-02,  4.73188978e-02,\n",
      "               -4.78086608e-03,  1.23990984e-01, -6.33448133e-03,\n",
      "                2.60600970e-02, -5.79547014e-02,  5.49954175e-03],\n",
      "              [-7.84833989e-02, -5.93232074e-02,  2.99962608e-02,\n",
      "                1.42996938e-02,  3.80191841e-03, -4.61435071e-02,\n",
      "                4.43054859e-02, -1.57497737e-02, -1.03153992e-01,\n",
      "               -4.21123227e-02, -3.72309465e-02,  5.03287402e-02,\n",
      "               -4.96887699e-02, -1.41743651e-02, -2.38823810e-02,\n",
      "               -1.56010072e-02, -2.51260725e-02, -3.61578134e-02,\n",
      "               -4.81286493e-02,  2.30264691e-02, -1.09295892e-02,\n",
      "               -1.31103972e-01, -9.96253411e-02, -2.53990371e-02,\n",
      "               -2.31715390e-02, -1.93317638e-02,  2.78760771e-02,\n",
      "                3.84191720e-02,  2.66108234e-02,  6.88051872e-02],\n",
      "              [-2.07345576e-02,  1.50378341e-02,  3.35503447e-02,\n",
      "               -6.12496191e-02, -1.04158127e-02,  1.93288392e-02,\n",
      "                2.72414473e-02, -3.70669984e-02,  3.12588296e-02,\n",
      "                1.07009726e-02,  3.77992898e-02, -1.48606956e-02,\n",
      "               -9.71185909e-02, -3.56871352e-02, -1.30117309e-01,\n",
      "               -2.39203922e-02,  7.33098152e-02, -1.98520024e-02,\n",
      "               -6.57703502e-03,  4.38204713e-02,  5.10647711e-03,\n",
      "               -3.76322642e-02,  7.52671685e-02, -4.98896138e-02,\n",
      "                2.53114532e-02,  2.91742274e-02, -5.06093289e-02,\n",
      "               -7.96247596e-02, -3.12741274e-02,  4.78879291e-02],\n",
      "              [ 1.33078969e-02,  1.63218888e-02, -7.93868317e-02,\n",
      "               -2.62537315e-02, -3.36051068e-02, -9.59050171e-03,\n",
      "               -1.43334457e-02,  8.27876500e-03,  4.48522962e-02,\n",
      "                6.29761507e-03, -3.32466164e-02, -1.10116822e-01,\n",
      "               -4.39677764e-02, -5.55083804e-02, -4.52448553e-02,\n",
      "               -1.23096683e-02,  1.69434841e-03, -2.52558044e-02,\n",
      "                2.06142418e-02, -7.09148363e-02, -1.16596010e-01,\n",
      "                1.09891647e-01,  3.17199005e-02,  2.48839120e-02,\n",
      "               -3.66662457e-03,  5.33646516e-02, -9.56330729e-02,\n",
      "                6.14302563e-02, -3.99350510e-02, -1.35126247e-02],\n",
      "              [-1.40902587e-02,  1.37397422e-02, -2.14896594e-02,\n",
      "                1.62691850e-02, -2.04656389e-02, -6.98061472e-02,\n",
      "                1.00323449e-03,  3.29072371e-02, -1.00066566e-03,\n",
      "               -3.74187525e-02,  8.07037355e-02,  1.60144961e-02,\n",
      "                1.15735618e-02,  3.13637565e-02,  4.03962952e-02,\n",
      "                6.17050812e-03, -6.20291610e-02, -7.31854844e-03,\n",
      "                1.11190105e-02, -3.21879138e-02, -1.65925918e-02,\n",
      "               -1.02411431e-02, -5.62949160e-02, -5.62644446e-02,\n",
      "               -2.85480411e-02,  5.38970193e-02, -6.94457810e-02,\n",
      "               -1.74103058e-02, -9.49887560e-05,  4.97759798e-02],\n",
      "              [ 4.47310875e-03,  4.90395975e-02,  3.34641512e-02,\n",
      "                7.97043963e-02,  6.64873364e-03,  8.32067767e-03,\n",
      "                3.96164226e-02,  8.83507415e-02, -2.27173562e-02,\n",
      "                2.01148073e-02,  1.90450204e-02,  1.82368215e-02,\n",
      "                2.40426602e-02, -4.87045161e-02,  6.38577278e-02,\n",
      "               -4.60390800e-02, -2.45576777e-03, -4.03024826e-02,\n",
      "               -8.90190721e-03, -2.69219864e-02,  2.03655949e-03,\n",
      "                3.53380240e-02, -2.11318639e-02,  2.09773324e-03,\n",
      "                4.18215202e-02, -5.76981108e-02, -3.50125709e-02,\n",
      "               -4.94139285e-02, -5.56521031e-02,  2.81641319e-02],\n",
      "              [ 2.11943711e-02,  6.38829994e-02, -2.86958841e-02,\n",
      "                2.42388293e-02, -4.59680515e-03,  1.80581520e-02,\n",
      "               -1.62902836e-02, -6.54235290e-02,  3.47917033e-02,\n",
      "                8.61927502e-02,  9.02886291e-02,  7.74122615e-03,\n",
      "               -2.31690807e-02,  6.82547073e-02,  8.94234244e-02,\n",
      "               -2.66693769e-03, -5.18252437e-03,  5.46651349e-02,\n",
      "               -4.83131922e-02,  9.79537157e-02,  5.13048765e-02,\n",
      "                4.09922217e-02,  1.23828637e-02,  4.96644652e-02,\n",
      "               -6.39777519e-03, -9.59639060e-03,  9.29709460e-03,\n",
      "               -1.60384930e-02, -1.03836673e-01, -6.58399651e-03],\n",
      "              [-4.16025847e-02, -3.43435346e-03,  3.72283580e-02,\n",
      "                2.93149188e-02,  2.32214894e-02, -5.99864185e-02,\n",
      "               -6.01315488e-02,  3.73302463e-02,  6.07343951e-02,\n",
      "               -3.45128023e-03,  4.96833940e-02, -7.81350502e-02,\n",
      "               -1.18766304e-02,  1.31774510e-01, -6.93117016e-03,\n",
      "               -4.08743352e-02,  5.25066507e-02, -2.84772783e-02,\n",
      "                7.35848301e-02, -6.28183705e-02,  2.99954778e-02,\n",
      "               -1.56555149e-02, -3.43626099e-02,  9.99819394e-03,\n",
      "               -3.38382885e-02, -7.09033944e-03,  1.35055721e-02,\n",
      "               -4.53871157e-02,  2.23546321e-02, -5.27681717e-03]]),\n",
      "        array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 12\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning check with dropout = \u001b[39m\u001b[38;5;124m'\u001b[39m, dropout)\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m FullyConnectedNet([H1, H2], input_dim\u001b[38;5;241m=\u001b[39mD, num_classes\u001b[38;5;241m=\u001b[39mC,\n\u001b[0;32m      9\u001b[0m                           weight_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-2\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[0;32m     10\u001b[0m                           dropout\u001b[38;5;241m=\u001b[39mdropout, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitial loss: \u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Relative errors should be around e-6 or less; Note that it's fine\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# if for dropout=1 you have W2 error be on the order of e-5.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\classifiers\\fc_net.py:377\u001b[0m, in \u001b[0;36mFullyConnectedNet.loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dropout:\n\u001b[0;32m    376\u001b[0m     dhidden \u001b[38;5;241m=\u001b[39m dropout_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n\u001b[1;32m--> 377\u001b[0m dhidden \u001b[38;5;241m=\u001b[39m \u001b[43mrelu_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalization \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    379\u001b[0m     dhidden, dgamma, dbeta \u001b[38;5;241m=\u001b[39m batchnorm_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\layers.py:131\u001b[0m, in \u001b[0;36mrelu_backward\u001b[1;34m(dout, cache)\u001b[0m\n\u001b[0;32m    129\u001b[0m x \u001b[38;5;241m=\u001b[39m cache\n\u001b[0;32m    130\u001b[0m ic(x)\n\u001b[1;32m--> 131\u001b[0m dx \u001b[38;5;241m=\u001b[39m dout \u001b[38;5;241m*\u001b[39m (\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m#                             END OF YOUR CODE                            #\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dx\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "for dropout in [1, 0.75, 0.5]:\n",
    "  print('Running check with dropout = ', dropout)\n",
    "  model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                            weight_scale=5e-2, dtype=np.float64,\n",
    "                            dropout=dropout, seed=123)\n",
    "\n",
    "  loss, grads = model.loss(X, y)\n",
    "  print('Initial loss: ', loss)\n",
    "  \n",
    "  # Relative errors should be around e-6 or less; Note that it's fine\n",
    "  # if for dropout=1 you have W2 error be on the order of e-5.\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите две двухслойные сети с dropout-слоем (вероятность отсева 0,25) и без на наборе из 500 изображений. Визуализируйте графики обучения. Сделайте выводы по результатам эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x: (array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "              [0., 0., 0., ..., 0., 0., 0.],\n",
      "              [0., 0., 0., ..., 0., 0., 0.],\n",
      "              ...,\n",
      "              [0., 0., 0., ..., 0., 0., 0.],\n",
      "              [0., 0., 0., ..., 0., 0., 0.],\n",
      "              [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
      "        array([[ 0.00417943,  0.013971  , -0.01785904, ...,  0.00977079,\n",
      "               -0.00345718, -0.00546486],\n",
      "              [ 0.00512453,  0.01404213,  0.00279914, ..., -0.00310411,\n",
      "               -0.02201058, -0.00604232],\n",
      "              [-0.00130501,  0.02884116,  0.00917584, ..., -0.00444533,\n",
      "                0.00148191,  0.01403515],\n",
      "              ...,\n",
      "              [ 0.00114734, -0.01547652,  0.01356354, ...,  0.00143373,\n",
      "               -0.00599072,  0.01589943],\n",
      "              [ 0.00833154,  0.00180847,  0.00808435, ..., -0.00684451,\n",
      "                0.00542312,  0.01817297],\n",
      "              [-0.00308257, -0.00281742,  0.00919512, ...,  0.00055839,\n",
      "                0.0013742 , -0.01318542]], dtype=float32),\n",
      "        array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "X shape: (100, 784)\n",
      "scores shape: (100, 10)\n",
      "Shape of x[0]: (500,)\n",
      "Shape of dout: (100, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "              0., 0., 0., 0., 0., 0., 0.], dtype=float32))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 24\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(dropout)\n\u001b[0;32m     17\u001b[0m solver \u001b[38;5;241m=\u001b[39m Solver(model, small_data,\n\u001b[0;32m     18\u001b[0m                 num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     19\u001b[0m                 update_rule\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m                 },\n\u001b[0;32m     23\u001b[0m                 verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, print_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m solvers[dropout] \u001b[38;5;241m=\u001b[39m solver\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:263\u001b[0m, in \u001b[0;36mSolver.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m num_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs \u001b[38;5;241m*\u001b[39m iterations_per_epoch\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# Maybe print training loss\u001b[39;00m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;129;01mand\u001b[39;00m t \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:181\u001b[0m, in \u001b[0;36mSolver._step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train[batch_mask]\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Compute loss and gradient\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_history\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# Perform a parameter update\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\classifiers\\fc_net.py:377\u001b[0m, in \u001b[0;36mFullyConnectedNet.loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dropout:\n\u001b[0;32m    376\u001b[0m     dhidden \u001b[38;5;241m=\u001b[39m dropout_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n\u001b[1;32m--> 377\u001b[0m dhidden \u001b[38;5;241m=\u001b[39m \u001b[43mrelu_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalization \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    379\u001b[0m     dhidden, dgamma, dbeta \u001b[38;5;241m=\u001b[39m batchnorm_backward(dhidden, caches\u001b[38;5;241m.\u001b[39mpop())\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\layers.py:131\u001b[0m, in \u001b[0;36mrelu_backward\u001b[1;34m(dout, cache)\u001b[0m\n\u001b[0;32m    129\u001b[0m x \u001b[38;5;241m=\u001b[39m cache\n\u001b[0;32m    130\u001b[0m ic(x)\n\u001b[1;32m--> 131\u001b[0m dx \u001b[38;5;241m=\u001b[39m dout \u001b[38;5;241m*\u001b[39m (\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m#                             END OF YOUR CODE                            #\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dx\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "# Train two identical nets, one with dropout and one without\n",
    "np.random.seed(231)\n",
    "num_train = 500\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "solvers = {}\n",
    "dropout_choices = [1, 0.25]\n",
    "for dropout in dropout_choices:\n",
    "  model = FullyConnectedNet([500], dropout=dropout)\n",
    "  print(dropout)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=25, batch_size=100,\n",
    "                  update_rule='adam',\n",
    "                  optim_config={\n",
    "                    'learning_rate': 5e-4,\n",
    "                  },\n",
    "                  verbose=True, print_every=100)\n",
    "  solver.train()\n",
    "  solvers[dropout] = solver\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m val_accs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dropout \u001b[38;5;129;01min\u001b[39;00m dropout_choices:\n\u001b[1;32m----> 6\u001b[0m   solver \u001b[38;5;241m=\u001b[39m \u001b[43msolvers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      7\u001b[0m   train_accs\u001b[38;5;241m.\u001b[39mappend(solver\u001b[38;5;241m.\u001b[39mtrain_acc_history[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      8\u001b[0m   val_accs\u001b[38;5;241m.\u001b[39mappend(solver\u001b[38;5;241m.\u001b[39mval_acc_history[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "# Plot train and validation accuracies of the two models\n",
    "\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for dropout in dropout_choices:\n",
    "  solver = solvers[dropout]\n",
    "  train_accs.append(solver.train_acc_history[-1])\n",
    "  val_accs.append(solver.val_acc_history[-1])\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "for dropout in dropout_choices:\n",
    "  plt.plot(solvers[dropout].train_acc_history, 'o', label='%.2f dropout' % dropout)\n",
    "plt.title('Train accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(ncol=2, loc='lower right')\n",
    "  \n",
    "plt.subplot(3, 1, 2)\n",
    "for dropout in dropout_choices:\n",
    "  plt.plot(solvers[dropout].val_acc_history, 'o', label='%.2f dropout' % dropout)\n",
    "plt.title('Val accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(ncol=2, loc='lower right')\n",
    "\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сверточные нейронные сети (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте прямой проход для сверточного слоя - функция conv_forward_naive в scripts/layers.py юПроверьте свою реализацию, запустив код ниже "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing conv_forward_naive\n",
      "difference:  2.2121476417505994e-08\n"
     ]
    }
   ],
   "source": [
    "x_shape = (2, 3, 4, 4)\n",
    "w_shape = (3, 3, 4, 4)\n",
    "x = np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape)\n",
    "b = np.linspace(-0.1, 0.2, num=3)\n",
    "\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "out, _ = conv_forward_naive(x, w, b, conv_param)\n",
    "correct_out = np.array([[[[-0.08759809, -0.10987781],\n",
    "                           [-0.18387192, -0.2109216 ]],\n",
    "                          [[ 0.21027089,  0.21661097],\n",
    "                           [ 0.22847626,  0.23004637]],\n",
    "                          [[ 0.50813986,  0.54309974],\n",
    "                           [ 0.64082444,  0.67101435]]],\n",
    "                         [[[-0.98053589, -1.03143541],\n",
    "                           [-1.19128892, -1.24695841]],\n",
    "                          [[ 0.69108355,  0.66880383],\n",
    "                           [ 0.59480972,  0.56776003]],\n",
    "                          [[ 2.36270298,  2.36904306],\n",
    "                           [ 2.38090835,  2.38247847]]]])\n",
    "\n",
    "# Compare your output to ours; difference should be around e-8\n",
    "print('Testing conv_forward_naive')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте обратный проход - функция conv_backward_naive в scripts/layers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing conv_backward_naive function\n",
      "dx error:  1.159803161159293e-08\n",
      "dw error:  2.2471264748452487e-10\n",
      "db error:  3.3726153958780465e-11\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(4, 3, 5, 5)\n",
    "w = np.random.randn(2, 3, 3, 3)\n",
    "b = np.random.randn(2,)\n",
    "dout = np.random.randn(4, 2, 5, 5)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_forward_naive(x, w, b, conv_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_forward_naive(x, w, b, conv_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_forward_naive(x, w, b, conv_param)[0], b, dout)\n",
    "\n",
    "out, cache = conv_forward_naive(x, w, b, conv_param)\n",
    "dx, dw, db = conv_backward_naive(dout, cache)\n",
    "\n",
    "# Your errors should be around e-8 or less.\n",
    "print('Testing conv_backward_naive function')\n",
    "print('dx error: ', rel_error(dx, dx_num))\n",
    "print('dw error: ', rel_error(dw, dw_num))\n",
    "print('db error: ', rel_error(db, db_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте прямой проход для max-pooling слоя -функция  max_pool_forward_naive в scripts/layers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing max_pool_forward_naive function:\n",
      "difference:  4.1666665157267834e-08\n"
     ]
    }
   ],
   "source": [
    "x_shape = (2, 3, 4, 4)\n",
    "x = np.linspace(-0.3, 0.4, num=np.prod(x_shape)).reshape(x_shape)\n",
    "pool_param = {'pool_width': 2, 'pool_height': 2, 'stride': 2}\n",
    "\n",
    "out, _ = max_pool_forward_naive(x, pool_param)\n",
    "\n",
    "correct_out = np.array([[[[-0.26315789, -0.24842105],\n",
    "                          [-0.20421053, -0.18947368]],\n",
    "                         [[-0.14526316, -0.13052632],\n",
    "                          [-0.08631579, -0.07157895]],\n",
    "                         [[-0.02736842, -0.01263158],\n",
    "                          [ 0.03157895,  0.04631579]]],\n",
    "                        [[[ 0.09052632,  0.10526316],\n",
    "                          [ 0.14947368,  0.16421053]],\n",
    "                         [[ 0.20842105,  0.22315789],\n",
    "                          [ 0.26736842,  0.28210526]],\n",
    "                         [[ 0.32631579,  0.34105263],\n",
    "                          [ 0.38526316,  0.4       ]]]])\n",
    "\n",
    "# Compare your output with ours. Difference should be on the order of e-8.\n",
    "print('Testing max_pool_forward_naive function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте обратный проход для max-pooling слоя в max_pool_backward_naive . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing max_pool_backward_naive function:\n",
      "dx error:  3.27562514223145e-12\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(3, 2, 8, 8)\n",
    "dout = np.random.randn(3, 2, 4, 4)\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: max_pool_forward_naive(x, pool_param)[0], x, dout)\n",
    "\n",
    "out, cache = max_pool_forward_naive(x, pool_param)\n",
    "dx = max_pool_backward_naive(dout, cache)\n",
    "\n",
    "# Your error should be on the order of e-12\n",
    "print('Testing max_pool_backward_naive function:')\n",
    "print('dx error: ', rel_error(dx, dx_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В скрипте scripts/fast_layers.py представлены быстрые реализации слоев свертки и пуллинга, написанных с использованием  Cython. \n",
    "\n",
    "Для компиляции выполните следующую команду в директории scripts\n",
    "\n",
    "```bash\n",
    "python setup.py build_ext --inplace\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните ваши реализации слоев свертки и пуллинга с быстрыми реализациями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== You can safely ignore the message below if you are NOT working on ConvolutionalNetworks.ipynb ===========\n",
      "\tYou will need to compile a Cython extension for a portion of this assignment.\n",
      "\tThe instructions to do this will be given in a section of the notebook below.\n",
      "\tThere will be an option for Colab users and another for Jupyter (local) users.\n",
      "Testing conv_forward_fast:\n",
      "Naive: 1.884638s\n",
      "Fast: 0.000000s\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaive: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (t1 \u001b[38;5;241m-\u001b[39m t0))\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFast: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (t2 \u001b[38;5;241m-\u001b[39m t1))\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpeedup: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[43m(\u001b[49m\u001b[43mt1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mt2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDifference: \u001b[39m\u001b[38;5;124m'\u001b[39m, rel_error(out_naive, out_fast))\n\u001b[0;32m     23\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time()\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# Rel errors should be around e-9 or less\n",
    "from scripts.fast_layers import conv_forward_fast, conv_backward_fast\n",
    "from time import time\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(100, 3, 31, 31)\n",
    "w = np.random.randn(25, 3, 3, 3)\n",
    "b = np.random.randn(25,)\n",
    "dout = np.random.randn(100, 25, 16, 16)\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "\n",
    "t0 = time()\n",
    "out_naive, cache_naive = conv_forward_naive(x, w, b, conv_param)\n",
    "t1 = time()\n",
    "out_fast, cache_fast = conv_forward_fast(x, w, b, conv_param)\n",
    "t2 = time()\n",
    "\n",
    "print('Testing conv_forward_fast:')\n",
    "print('Naive: %fs' % (t1 - t0))\n",
    "print('Fast: %fs' % (t2 - t1))\n",
    "print('Speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('Difference: ', rel_error(out_naive, out_fast))\n",
    "\n",
    "t0 = time()\n",
    "dx_naive, dw_naive, db_naive = conv_backward_naive(dout, cache_naive)\n",
    "t1 = time()\n",
    "dx_fast, dw_fast, db_fast = conv_backward_fast(dout, cache_fast)\n",
    "t2 = time()\n",
    "\n",
    "print('\\nTesting conv_backward_fast:')\n",
    "print('Naive: %fs' % (t1 - t0))\n",
    "print('Fast: %fs' % (t2 - t1))\n",
    "print('Speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('dx difference: ', rel_error(dx_naive, dx_fast))\n",
    "print('dw difference: ', rel_error(dw_naive, dw_fast))\n",
    "print('db difference: ', rel_error(db_naive, db_fast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing pool_forward_fast:\n",
      "Naive: 0.140788s\n",
      "fast: 0.000000s\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaive: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (t1 \u001b[38;5;241m-\u001b[39m t0))\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfast: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (t2 \u001b[38;5;241m-\u001b[39m t1))\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeedup: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[43m(\u001b[49m\u001b[43mt1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mt2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifference: \u001b[39m\u001b[38;5;124m'\u001b[39m, rel_error(out_naive, out_fast))\n\u001b[0;32m     20\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time()\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# Relative errors should be close to 0.0\n",
    "from scripts.fast_layers import max_pool_forward_fast, max_pool_backward_fast\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(100, 3, 32, 32)\n",
    "dout = np.random.randn(100, 3, 16, 16)\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "t0 = time()\n",
    "out_naive, cache_naive = max_pool_forward_naive(x, pool_param)\n",
    "t1 = time()\n",
    "out_fast, cache_fast = max_pool_forward_fast(x, pool_param)\n",
    "t2 = time()\n",
    "\n",
    "print('Testing pool_forward_fast:')\n",
    "print('Naive: %fs' % (t1 - t0))\n",
    "print('fast: %fs' % (t2 - t1))\n",
    "print('speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('difference: ', rel_error(out_naive, out_fast))\n",
    "\n",
    "t0 = time()\n",
    "dx_naive = max_pool_backward_naive(dout, cache_naive)\n",
    "t1 = time()\n",
    "dx_fast = max_pool_backward_fast(dout, cache_fast)\n",
    "t2 = time()\n",
    "\n",
    "print('\\nTesting pool_backward_fast:')\n",
    "print('Naive: %fs' % (t1 - t0))\n",
    "print('fast: %fs' % (t2 - t1))\n",
    "print('speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('dx difference: ', rel_error(dx_naive, dx_fast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В layer_utils.py вы можете найти  часто используемые комбинации слоев, используемых в сверточных сетях. Ознакомьтесь с ними и запустите код ниже для проверки их работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'col2im_6d_cython' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m pool_param \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpool_height\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpool_width\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstride\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m}\n\u001b[0;32m     10\u001b[0m out, cache \u001b[38;5;241m=\u001b[39m conv_relu_pool_forward(x, w, b, conv_param, pool_param)\n\u001b[1;32m---> 11\u001b[0m dx, dw, db \u001b[38;5;241m=\u001b[39m \u001b[43mconv_relu_pool_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m dx_num \u001b[38;5;241m=\u001b[39m eval_numerical_gradient_array(\u001b[38;5;28;01mlambda\u001b[39;00m x: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[\u001b[38;5;241m0\u001b[39m], x, dout)\n\u001b[0;32m     14\u001b[0m dw_num \u001b[38;5;241m=\u001b[39m eval_numerical_gradient_array(\u001b[38;5;28;01mlambda\u001b[39;00m w: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[\u001b[38;5;241m0\u001b[39m], w, dout)\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts\\layer_utils.py:109\u001b[0m, in \u001b[0;36mconv_relu_pool_backward\u001b[1;34m(dout, cache)\u001b[0m\n\u001b[0;32m    107\u001b[0m ds \u001b[38;5;241m=\u001b[39m max_pool_backward_fast(dout, pool_cache)\n\u001b[0;32m    108\u001b[0m da \u001b[38;5;241m=\u001b[39m relu_backward(ds, relu_cache)\n\u001b[1;32m--> 109\u001b[0m dx, dw, db \u001b[38;5;241m=\u001b[39m \u001b[43mconv_backward_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dx, dw, db\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts\\fast_layers.py:103\u001b[0m, in \u001b[0;36mconv_backward_strides\u001b[1;34m(dout, cache)\u001b[0m\n\u001b[0;32m    101\u001b[0m dx_cols \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mreshape(F, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mdot(dout_reshaped)\n\u001b[0;32m    102\u001b[0m dx_cols\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m=\u001b[39m (C, HH, WW, N, out_h, out_w)\n\u001b[1;32m--> 103\u001b[0m dx \u001b[38;5;241m=\u001b[39m \u001b[43mcol2im_6d_cython\u001b[49m(dx_cols, N, C, H, W, HH, WW, pad, stride)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dx, dw, db\n",
      "\u001b[1;31mNameError\u001b[0m: name 'col2im_6d_cython' is not defined"
     ]
    }
   ],
   "source": [
    "from scripts.layer_utils import conv_relu_pool_forward, conv_relu_pool_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 3, 16, 16)\n",
    "w = np.random.randn(3, 3, 3, 3)\n",
    "b = np.random.randn(3,)\n",
    "dout = np.random.randn(2, 3, 8, 8)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "out, cache = conv_relu_pool_forward(x, w, b, conv_param, pool_param)\n",
    "dx, dw, db = conv_relu_pool_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], b, dout)\n",
    "\n",
    "# Relative errors should be around e-8 or less\n",
    "print('Testing conv_relu_pool')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'col2im_6d_cython' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m conv_param \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstride\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpad\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m}\n\u001b[0;32m      9\u001b[0m out, cache \u001b[38;5;241m=\u001b[39m conv_relu_forward(x, w, b, conv_param)\n\u001b[1;32m---> 10\u001b[0m dx, dw, db \u001b[38;5;241m=\u001b[39m \u001b[43mconv_relu_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m dx_num \u001b[38;5;241m=\u001b[39m eval_numerical_gradient_array(\u001b[38;5;28;01mlambda\u001b[39;00m x: conv_relu_forward(x, w, b, conv_param)[\u001b[38;5;241m0\u001b[39m], x, dout)\n\u001b[0;32m     13\u001b[0m dw_num \u001b[38;5;241m=\u001b[39m eval_numerical_gradient_array(\u001b[38;5;28;01mlambda\u001b[39;00m w: conv_relu_forward(x, w, b, conv_param)[\u001b[38;5;241m0\u001b[39m], w, dout)\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts\\layer_utils.py:62\u001b[0m, in \u001b[0;36mconv_relu_backward\u001b[1;34m(dout, cache)\u001b[0m\n\u001b[0;32m     60\u001b[0m conv_cache, relu_cache \u001b[38;5;241m=\u001b[39m cache\n\u001b[0;32m     61\u001b[0m da \u001b[38;5;241m=\u001b[39m relu_backward(dout, relu_cache)\n\u001b[1;32m---> 62\u001b[0m dx, dw, db \u001b[38;5;241m=\u001b[39m \u001b[43mconv_backward_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dx, dw, db\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts\\fast_layers.py:103\u001b[0m, in \u001b[0;36mconv_backward_strides\u001b[1;34m(dout, cache)\u001b[0m\n\u001b[0;32m    101\u001b[0m dx_cols \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mreshape(F, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mdot(dout_reshaped)\n\u001b[0;32m    102\u001b[0m dx_cols\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m=\u001b[39m (C, HH, WW, N, out_h, out_w)\n\u001b[1;32m--> 103\u001b[0m dx \u001b[38;5;241m=\u001b[39m \u001b[43mcol2im_6d_cython\u001b[49m(dx_cols, N, C, H, W, HH, WW, pad, stride)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dx, dw, db\n",
      "\u001b[1;31mNameError\u001b[0m: name 'col2im_6d_cython' is not defined"
     ]
    }
   ],
   "source": [
    "from scripts.layer_utils import conv_relu_forward, conv_relu_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 3, 8, 8)\n",
    "w = np.random.randn(3, 3, 3, 3)\n",
    "b = np.random.randn(3,)\n",
    "dout = np.random.randn(2, 3, 8, 8)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "out, cache = conv_relu_forward(x, w, b, conv_param)\n",
    "dx, dw, db = conv_relu_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_relu_forward(x, w, b, conv_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_relu_forward(x, w, b, conv_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_relu_forward(x, w, b, conv_param)[0], b, dout)\n",
    "\n",
    "# Relative errors should be around e-8 or less\n",
    "print('Testing conv_relu:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите реализацию класса ThreeLayerConvNet в scripts/classifiers/cnn.py . Вы можете использовать готовые реализации слоев и их комбинаций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте вашу реализацию. Ожидается, что значение функции потерь softmax будет порядка `log(C)` для `C` классов для случая без регуляризации. В случае регуляризации значение функции потерь должно немного возрасти. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'W1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(N, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m10\u001b[39m, size\u001b[38;5;241m=\u001b[39mN)\n\u001b[1;32m----> 7\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitial loss (no regularization): \u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mreg \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\classifiers\\cnn.py:82\u001b[0m, in \u001b[0;36mThreeLayerConvNet.loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    Evaluate loss and gradient for the three-layer convolutional network.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m    Input / output: Same API as TwoLayerNet in fc_net.py.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     W1, b1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     83\u001b[0m     W2, b2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     84\u001b[0m     W3, b3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW3\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'W1'"
     ]
    }
   ],
   "source": [
    "model = ThreeLayerConvNet()\n",
    "\n",
    "N = 50\n",
    "X = np.random.randn(N, 3, 32, 32)\n",
    "y = np.random.randint(10, size=N)\n",
    "\n",
    "loss, grads = model.loss(X, y)\n",
    "print('Initial loss (no regularization): ', loss)\n",
    "\n",
    "model.reg = 0.5\n",
    "loss, grads = model.loss(X, y)\n",
    "print('Initial loss (with regularization): ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте реализацию обратного прохода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'W1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 12\u001b[0m\n\u001b[0;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(num_classes, size\u001b[38;5;241m=\u001b[39mnum_inputs)\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m ThreeLayerConvNet(num_filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, filter_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     10\u001b[0m                           input_dim\u001b[38;5;241m=\u001b[39minput_dim, hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m,\n\u001b[0;32m     11\u001b[0m                           dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m---> 12\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Errors should be small, but correct implementations may have\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# relative errors up to the order of e-2\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(grads):\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\classifiers\\cnn.py:82\u001b[0m, in \u001b[0;36mThreeLayerConvNet.loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    Evaluate loss and gradient for the three-layer convolutional network.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m    Input / output: Same API as TwoLayerNet in fc_net.py.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     W1, b1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     83\u001b[0m     W2, b2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     84\u001b[0m     W3, b3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW3\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'W1'"
     ]
    }
   ],
   "source": [
    "num_inputs = 2\n",
    "input_dim = (3, 16, 16)\n",
    "reg = 0.0\n",
    "num_classes = 10\n",
    "np.random.seed(231)\n",
    "X = np.random.randn(num_inputs, *input_dim)\n",
    "y = np.random.randint(num_classes, size=num_inputs)\n",
    "\n",
    "model = ThreeLayerConvNet(num_filters=3, filter_size=3,\n",
    "                          input_dim=input_dim, hidden_dim=7,\n",
    "                          dtype=np.float64)\n",
    "loss, grads = model.loss(X, y)\n",
    "# Errors should be small, but correct implementations may have\n",
    "# relative errors up to the order of e-2\n",
    "for param_name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, model.params[param_name], verbose=False, h=1e-6)\n",
    "    e = rel_error(param_grad_num, grads[param_name])\n",
    "    print('%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте добиться эффекта переобучения. Обучите модель на небольшом наборе данных.Сравните значения accuracy на обучающих данных и на валидационных. Визуализируйте графики обучения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'W1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 20\u001b[0m\n\u001b[0;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m ThreeLayerConvNet(weight_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m)\n\u001b[0;32m     13\u001b[0m solver \u001b[38;5;241m=\u001b[39m Solver(model, small_data,\n\u001b[0;32m     14\u001b[0m                 num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     15\u001b[0m                 update_rule\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m                 },\n\u001b[0;32m     19\u001b[0m                 verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, print_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:263\u001b[0m, in \u001b[0;36mSolver.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m num_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs \u001b[38;5;241m*\u001b[39m iterations_per_epoch\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# Maybe print training loss\u001b[39;00m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;129;01mand\u001b[39;00m t \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:181\u001b[0m, in \u001b[0;36mSolver._step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train[batch_mask]\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Compute loss and gradient\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_history\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# Perform a parameter update\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\classifiers\\cnn.py:82\u001b[0m, in \u001b[0;36mThreeLayerConvNet.loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    Evaluate loss and gradient for the three-layer convolutional network.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m    Input / output: Same API as TwoLayerNet in fc_net.py.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     W1, b1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     83\u001b[0m     W2, b2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     84\u001b[0m     W3, b3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW3\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'W1'"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "num_train = 100\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "model = ThreeLayerConvNet(weight_scale=1e-2)\n",
    "\n",
    "solver = Solver(model, small_data,\n",
    "                num_epochs=15, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=1)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'W1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Print final training accuracy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSmall data training accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m----> 4\u001b[0m     \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmall_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmall_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:247\u001b[0m, in \u001b[0;36mSolver.check_accuracy\u001b[1;34m(self, X, y, num_samples, batch_size)\u001b[0m\n\u001b[0;32m    245\u001b[0m     start \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m*\u001b[39m batch_size\n\u001b[0;32m    246\u001b[0m     end \u001b[38;5;241m=\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size\n\u001b[1;32m--> 247\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m     y_pred\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39margmax(scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    249\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack(y_pred)\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\classifiers\\cnn.py:82\u001b[0m, in \u001b[0;36mThreeLayerConvNet.loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    Evaluate loss and gradient for the three-layer convolutional network.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m    Input / output: Same API as TwoLayerNet in fc_net.py.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     W1, b1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     83\u001b[0m     W2, b2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     84\u001b[0m     W3, b3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW3\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'W1'"
     ]
    }
   ],
   "source": [
    "# Print final training accuracy\n",
    "print(\n",
    "    \"Small data training accuracy:\",\n",
    "    solver.check_accuracy(small_data['X_train'], small_data['y_train'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'W1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Print final validation accuracy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSmall data validation accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m----> 4\u001b[0m     \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmall_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX_val\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmall_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_val\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:247\u001b[0m, in \u001b[0;36mSolver.check_accuracy\u001b[1;34m(self, X, y, num_samples, batch_size)\u001b[0m\n\u001b[0;32m    245\u001b[0m     start \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m*\u001b[39m batch_size\n\u001b[0;32m    246\u001b[0m     end \u001b[38;5;241m=\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size\n\u001b[1;32m--> 247\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m     y_pred\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39margmax(scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    249\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack(y_pred)\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\classifiers\\cnn.py:82\u001b[0m, in \u001b[0;36mThreeLayerConvNet.loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    Evaluate loss and gradient for the three-layer convolutional network.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m    Input / output: Same API as TwoLayerNet in fc_net.py.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     W1, b1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     83\u001b[0m     W2, b2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     84\u001b[0m     W3, b3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW3\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'W1'"
     ]
    }
   ],
   "source": [
    "# Print final validation accuracy\n",
    "print(\n",
    "    \"Small data validation accuracy:\",\n",
    "    solver.check_accuracy(small_data['X_val'], small_data['y_val'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(solver.train_acc_history, '-o')\n",
    "plt.plot(solver.val_acc_history, '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите сеть на полном наборе данных. Выведите accuracy на обучающей и валидационной выборках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'W1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m ThreeLayerConvNet(weight_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, reg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m      3\u001b[0m solver \u001b[38;5;241m=\u001b[39m Solver(model, data,\n\u001b[0;32m      4\u001b[0m                 num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m      5\u001b[0m                 update_rule\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m                 },\n\u001b[0;32m      9\u001b[0m                 verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, print_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:263\u001b[0m, in \u001b[0;36mSolver.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m num_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs \u001b[38;5;241m*\u001b[39m iterations_per_epoch\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# Maybe print training loss\u001b[39;00m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;129;01mand\u001b[39;00m t \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\solver.py:181\u001b[0m, in \u001b[0;36mSolver._step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train[batch_mask]\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Compute loss and gradient\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_history\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# Perform a parameter update\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\79270\\Documents\\AppliedMath_CS_3\\DL_master_SamUni\\HW3\\scripts_\\classifiers\\cnn.py:82\u001b[0m, in \u001b[0;36mThreeLayerConvNet.loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    Evaluate loss and gradient for the three-layer convolutional network.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m    Input / output: Same API as TwoLayerNet in fc_net.py.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     W1, b1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     83\u001b[0m     W2, b2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     84\u001b[0m     W3, b3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW3\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'W1'"
     ]
    }
   ],
   "source": [
    "model = ThreeLayerConvNet(weight_scale=0.001, hidden_dim=500, reg=0.001)\n",
    "\n",
    "solver = Solver(model, data,\n",
    "                num_epochs=1, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=20)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final training accuracy\n",
    "print(\n",
    "    \"Full data training accuracy:\",\n",
    "    solver.check_accuracy(small_data['X_train'], small_data['y_train'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final validation accuracy\n",
    "print(\n",
    "    \"Full data validation accuracy:\",\n",
    "    solver.check_accuracy(data['X_val'], data['y_val'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте фильтры на первом слое обученной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.vis_utils import visualize_grid\n",
    "\n",
    "grid = visualize_grid(model.params['W1'].transpose(0, 2, 3, 1))\n",
    "plt.imshow(grid.astype('uint8'))\n",
    "plt.axis('off')\n",
    "plt.gcf().set_size_inches(5, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
